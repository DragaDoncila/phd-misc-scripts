{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmvc_metrics import load_sol\n",
    "from ctc_timings import get_im_centers, get_graph\n",
    "from oracle import get_oracle, get_gt_graph\n",
    "from tqdm import tqdm\n",
    "from traccuracy.loaders import load_ctc_data\n",
    "from visualize_lp_solution import load_tiff_frames\n",
    "\n",
    "import json\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_DIR = '/media/ddon0001/Elements/BMVC/data/ELEPHANT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_summary_df = pd.read_csv('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/ds_summary.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/ctc_metrics.json', 'r') as f:\n",
    "#     metric_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m seg_pth \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DATA_DIR, ds_name), \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mseq\u001b[39m}\u001b[39;00m\u001b[39m_ST/SEG/\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m start_t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 15\u001b[0m coords, min_t, max_t, corners \u001b[39m=\u001b[39m get_im_centers(seg_pth)\n\u001b[1;32m     16\u001b[0m duration \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_t\n\u001b[1;32m     18\u001b[0m used_ds_names\u001b[39m.\u001b[39mappend(ds_name)\n",
      "File \u001b[0;32m/media/ddon0001/Elements/BMVC/misc-scripts/ctc_timings.py:35\u001b[0m, in \u001b[0;36mget_im_centers\u001b[0;34m(im_pth, return_ims)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_im_centers\u001b[39m(im_pth, return_ims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 35\u001b[0m     im_arr \u001b[39m=\u001b[39m load_tiff_frames(im_pth)\n\u001b[1;32m     36\u001b[0m     coords_df, min_t, max_t, corners \u001b[39m=\u001b[39m extract_im_centers(im_arr)\n\u001b[1;32m     37\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_ims:\n",
      "File \u001b[0;32m/media/ddon0001/Elements/BMVC/misc-scripts/ims_to_graph.py:35\u001b[0m, in \u001b[0;36mload_tiff_frames\u001b[0;34m(im_dir)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m im\u001b[39m.\u001b[39mpages:\n\u001b[1;32m     34\u001b[0m             im_array[i] \u001b[39m=\u001b[39m page\u001b[39m.\u001b[39masarray()\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m im_array\n",
      "File \u001b[0;32m/media/ddon0001/Elements/BMVC/misc-scripts/ims_to_graph.py:35\u001b[0m, in \u001b[0;36mload_tiff_frames\u001b[0;34m(im_dir)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m im\u001b[39m.\u001b[39mpages:\n\u001b[1;32m     34\u001b[0m             im_array[i] \u001b[39m=\u001b[39m page\u001b[39m.\u001b[39masarray()\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m im_array\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/bmvc/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bmvc/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# used_ds_names = []\n",
    "# used_seqs = []\n",
    "# n_frames = []\n",
    "# im_dim = []\n",
    "# min_cells = []\n",
    "# max_cells = []\n",
    "# load_times = []\n",
    "\n",
    "# for i, row in tqdm(enumerate(ds_summary_df.itertuples(), 1), desc='Building & Solving'):\n",
    "#     ds_name = row.ds_name\n",
    "#     seq = '{0:02}'.format(row.seq)\n",
    "#     min_t = 0\n",
    "#     max_t = row.n_frames - 1\n",
    "#     corners = [(0, 0), eval(row.im_dim)]\n",
    "#     key = f'{ds_name}_{row.seq}'\n",
    "#     if isinstance(metric_info[key], dict):\n",
    "#         print(f\"Skipping {key}. Already computed metrics.\")\n",
    "#         continue\n",
    "    \n",
    "#     csv_pth = os.path.join(ROOT_DATA_DIR, f'{ds_name}_{seq}_coords.csv')\n",
    "#     seg_pth = os.path.join(os.path.join(ROOT_DATA_DIR, ds_name), f'{seq}_ST/SEG/')\n",
    "#     start_t = time.time()\n",
    "#     coords, min_t, max_t, corners = get_im_centers(seg_pth)\n",
    "#     duration = time.time() - start_t\n",
    "\n",
    "#     used_ds_names.append(ds_name)\n",
    "#     used_seqs.append(seq)        \n",
    "#     n_frames.append(max_t - min_t + 1)\n",
    "#     im_dim.append(corners[1])\n",
    "#     n_cells_per_frame = coords.groupby('t').size()\n",
    "#     min_cells.append(n_cells_per_frame.min())\n",
    "#     max_cells.append(n_cells_per_frame.max())\n",
    "#     load_times.append(duration)\n",
    "#     coords.to_csv(csv_pth)\n",
    "\n",
    "# ds_summary_df = pd.DataFrame({\n",
    "#     'ds_name': ds_names,\n",
    "#     'seq': seqs,\n",
    "#     'n_frames': n_frames,\n",
    "#     'im_dim': im_dim,\n",
    "#     'min_cells': min_cells,\n",
    "#     'max_cells': max_cells,\n",
    "#     'load_time': load_times\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(used_ds_names)):\n",
    "#     name = used_ds_names[i]\n",
    "#     seq = used_seqs[i]\n",
    "#     row_idx = ds_summary_df[(ds_summary_df.ds_name == name) & (ds_summary_df.seq == int(seq))].index[0]\n",
    "#     ds_summary_df.at[row_idx,'load_time']=load_times[i]\n",
    "#     ds_summary_df.at[row_idx, 'min_cells'] = min_cells[i]\n",
    "#     ds_summary_df.at[row_idx, 'max_cells'] = max_cells[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_summary_df.to_csv('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/ds_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and solve model for each sequence, starting with the smallest in number of frames\n",
    "# ds_summary_df = ds_summary_df.sort_values(by='n_frames')\n",
    "# ds_names_used = []\n",
    "# ds_seqs_used = []\n",
    "# build_times = []\n",
    "# solve_times = []\n",
    "# store_times = []\n",
    "# for i, row in tqdm(enumerate(ds_summary_df.itertuples(), 1), desc='Building & Solving'):\n",
    "#     ds_name = row.ds_name\n",
    "#     seq = row.seq\n",
    "#     min_t = 0\n",
    "#     max_t = row.n_frames - 1\n",
    "#     corners = [(0, 0), eval(row.im_dim)]\n",
    "#     key = f'{ds_name}_{seq}'\n",
    "#     if isinstance(metric_info[key], dict):\n",
    "#         print(f\"Skipping {key}. Already computed metrics.\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"Re-solving {key}.\")\n",
    "#     ds_seqs_used.append(seq)\n",
    "#     ds_names_used.append(ds_name)\n",
    "    \n",
    "#     sol_dir = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_RES/'.format(seq))\n",
    "#     os.makedirs(sol_dir, exist_ok=True)\n",
    "#     sol_pth = os.path.join(sol_dir, 'full_solution.graphml')\n",
    "\n",
    "#     # read coords\n",
    "#     coords_path = os.path.join(ROOT_DATA_DIR, '{0}_{1:02}_coords.csv'.format(ds_name, seq))\n",
    "#     coords = pd.read_csv(coords_path)\n",
    "    \n",
    "#     # build graph\n",
    "#     graph, build_time = get_graph(coords, min_t, max_t, corners)\n",
    "#     build_times.append(build_time)\n",
    "\n",
    "#     # solve model\n",
    "#     m, flow = graph._to_gurobi_model()\n",
    "#     m.Params.LogToConsole = 0\n",
    "#     m.optimize()\n",
    "#     if m.Status == 3:\n",
    "#         infinite_cost_edges = graph._g.es.select(cost_ge=1e10)\n",
    "#         graph._g.delete_edges(infinite_cost_edges)\n",
    "#         m, flow = graph._to_gurobi_model()\n",
    "#         m.optimize()\n",
    "#         if m.Status != 2:\n",
    "#             raise ValueError(f\"Attempted to remove infinite cost edges but model for {key} was still not solved.\")\n",
    "#     solve_times.append(m.Runtime)\n",
    "    \n",
    "#     # store on graph\n",
    "#     store_time = graph.store_solution(m)\n",
    "#     store_times.append(store_time)\n",
    "    \n",
    "#     # save solution graph\n",
    "#     nx_g = graph.convert_sol_igraph_to_nx()\n",
    "#     nx.write_graphml_lxml(nx_g, sol_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building kD trees:  21%|██▏       | 376/1764 [00:20<01:15, 18.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m coords \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(coords_path)\n\u001b[1;32m     12\u001b[0m \u001b[39m# build graph\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m graph, build_time \u001b[39m=\u001b[39m get_graph(coords, min_t, max_t, corners)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(build_time)\n",
      "File \u001b[0;32m/media/ddon0001/Elements/BMVC/misc-scripts/ctc_timings.py:43\u001b[0m, in \u001b[0;36mget_graph\u001b[0;34m(coords, min_t, max_t, corners)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_graph\u001b[39m(coords, min_t, max_t, corners):\n\u001b[1;32m     42\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 43\u001b[0m     graph \u001b[39m=\u001b[39m FlowGraph(corners, coords, min_t\u001b[39m=\u001b[39;49mmin_t, max_t\u001b[39m=\u001b[39;49mmax_t, migration_only\u001b[39m=\u001b[39;49mMIGRATION_ONLY)\n\u001b[1;32m     44\u001b[0m     end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     45\u001b[0m     build_duration \u001b[39m=\u001b[39m end \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/media/ddon0001/Elements/BMVC/misc-scripts/flow_graph.py:128\u001b[0m, in \u001b[0;36mFlowGraph.__init__\u001b[0;34m(self, im_dim, coords, min_t, max_t, pixel_vals, migration_only)\u001b[0m\n\u001b[1;32m    126\u001b[0m     pixel_vals \u001b[39m=\u001b[39m coords[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_nodes(coords, pixel_vals)\n\u001b[0;32m--> 128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kdt_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_trees()\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_edges()\n",
      "File \u001b[0;32m/media/ddon0001/Elements/BMVC/misc-scripts/flow_graph.py:138\u001b[0m, in \u001b[0;36mFlowGraph._build_trees\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m kd_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tqdm(\n\u001b[1;32m    136\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_t, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_t \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), total\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBuilding kD trees\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m ):\n\u001b[0;32m--> 138\u001b[0m     tree, indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_tree_at_t(t)\n\u001b[1;32m    139\u001b[0m     kd_dict[t] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtree\u001b[39m\u001b[39m\"\u001b[39m: tree, \u001b[39m\"\u001b[39m\u001b[39mindices\u001b[39m\u001b[39m\"\u001b[39m: indices}\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m kd_dict\n",
      "File \u001b[0;32m/media/ddon0001/Elements/BMVC/misc-scripts/flow_graph.py:151\u001b[0m, in \u001b[0;36mFlowGraph._build_tree_at_t\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_tree_at_t\u001b[39m(\u001b[39mself\u001b[39m, t):\n\u001b[1;32m    143\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get tree and vertex indices for a given t.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \n\u001b[1;32m    145\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39m        Tuple(kdtree, np.ndarray): tree and vertex indices for tree coordinates\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     frame_vertices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_g\u001b[39m.\u001b[39;49mvs(t\u001b[39m=\u001b[39;49mt)\n\u001b[1;32m    152\u001b[0m     frame_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray([v\u001b[39m.\u001b[39mindex \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m frame_vertices])\n\u001b[1;32m    153\u001b[0m     frame_coords \u001b[39m=\u001b[39m frame_vertices[\u001b[39m\"\u001b[39m\u001b[39mcoords\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/bmvc/lib/python3.9/site-packages/igraph/seq.py:272\u001b[0m, in \u001b[0;36mVertexSeq.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m    268\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Shorthand notation to select()\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39m    This method simply passes all its arguments to L{VertexSeq.select()}.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselect(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/bmvc/lib/python3.9/site-packages/igraph/seq.py:262\u001b[0m, in \u001b[0;36mVertexSeq.select\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m         values \u001b[39m=\u001b[39m vs[attr]\n\u001b[0;32m--> 262\u001b[0m     filtered_idxs \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values) \u001b[39mif\u001b[39;00m func(v, value)]\n\u001b[1;32m    263\u001b[0m     vs \u001b[39m=\u001b[39m vs\u001b[39m.\u001b[39mselect(filtered_idxs)\n\u001b[1;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m vs\n",
      "File \u001b[0;32m~/miniconda3/envs/bmvc/lib/python3.9/site-packages/igraph/seq.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m         values \u001b[39m=\u001b[39m vs[attr]\n\u001b[0;32m--> 262\u001b[0m     filtered_idxs \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values) \u001b[39mif\u001b[39;00m func(v, value)]\n\u001b[1;32m    263\u001b[0m     vs \u001b[39m=\u001b[39m vs\u001b[39m.\u001b[39mselect(filtered_idxs)\n\u001b[1;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m vs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds_name = 'BF-C2DL-HSC'\n",
    "seq = 2\n",
    "min_t = 0\n",
    "max_t = 1763\n",
    "corners = [(0, 0), (1010, 1010)]\n",
    "key = f'{ds_name}_{seq}'\n",
    "\n",
    "# read coords\n",
    "coords_path = os.path.join(ROOT_DATA_DIR, '{0}_{1:02}_coords.csv'.format(ds_name, seq))\n",
    "coords = pd.read_csv(coords_path)\n",
    "\n",
    "# build graph\n",
    "graph, build_time = get_graph(coords, min_t, max_t, corners)\n",
    "print(build_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(ds_names_used)):\n",
    "#     name = ds_names_used[i]\n",
    "#     seq = ds_seqs_used[i]\n",
    "#     row_idx = ds_summary_df[(ds_summary_df.ds_name == name) & (ds_summary_df.seq == int(seq))].index[0]\n",
    "#     ds_summary_df.at[row_idx,'build_time']= build_times[i]\n",
    "#     ds_summary_df.at[row_idx, 'solve_time'] = solve_times[i]\n",
    "#     ds_summary_df.at[row_idx, 'store_time'] = store_times[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_summary_df.to_csv('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/ds_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges = {}\n",
    "# for i, row in enumerate(ds_summary_df.itertuples(), 1):\n",
    "#     ds_name = row.ds_name\n",
    "#     seq = row.seq\n",
    "#     merges[f'{ds_name}_{seq}'] = {}\n",
    "    \n",
    "#     sol_dir = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_RES/'.format(seq))\n",
    "#     sol_pth = os.path.join(sol_dir, 'full_solution.graphml')\n",
    "#     seg_pth = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_ST/SEG/'.format(seq))\n",
    "#     gt_pth = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_GT/TRA/'.format(seq))\n",
    "    \n",
    "#     # load solution, check the number of merges\n",
    "#     if not os.path.exists(sol_pth):\n",
    "#         merges[f'{ds_name}_{seq}']['n_merges'] = -1\n",
    "#         merges[f'{ds_name}_{seq}']['merge_nodes'] = []\n",
    "#     else:\n",
    "#         sol_data = load_sol(sol_pth, seg_pth)\n",
    "#         sol = sol_data.tracking_graph.graph\n",
    "#         oracle_node_df = pd.DataFrame.from_dict(sol.nodes, orient='index')\n",
    "        \n",
    "#         merge_nodes = [node for node in sol.nodes if len(sol.in_edges(node)) > 1]\n",
    "#         merges[f'{ds_name}_{seq}']['n_merges'] = len(merge_nodes)\n",
    "#         merges[f'{ds_name}_{seq}']['merge_nodes'] = merge_nodes\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/merge_info.json', 'r') as f:\n",
    "    merges = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oracles = {}\n",
    "# ds_summary_df = ds_summary_df.sort_values(by='n_frames')\n",
    "# oracle_pth = '/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/oracles.json'\n",
    "# for i, row in enumerate(ds_summary_df.itertuples(), 1):\n",
    "#     ds_name = row.ds_name\n",
    "#     seq = row.seq\n",
    "#     key = f'{ds_name}_{seq}'\n",
    "\n",
    "#     sol_dir = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_RES/'.format(seq))\n",
    "#     sol_pth = os.path.join(sol_dir, 'full_solution.graphml')\n",
    "#     seg_pth = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_ST/SEG/'.format(seq))\n",
    "#     gt_pth = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_GT/TRA/'.format(seq))\n",
    "\n",
    "#     if merges[key]['n_merges'] and \\\n",
    "#         metric_info[key] is not None and \\\n",
    "#             metric_info[key]['DET'] < 1:\n",
    "#         print(f\"Running oracle for {key}\")\n",
    "#         sol_data = load_sol(sol_pth, seg_pth)\n",
    "#         sol = sol_data.tracking_graph.graph\n",
    "#         sol_ims = sol_data.segmentation\n",
    "        \n",
    "#         oracle_node_df = pd.DataFrame.from_dict(sol.nodes, orient='index')\n",
    "#         merge_node_ids = merges[key]['merge_nodes']\n",
    "#         gt_data = load_ctc_data(gt_pth)\n",
    "#         gt_graph = gt_data.tracking_graph.graph\n",
    "#         gt_ims = gt_data.segmentation\n",
    "        \n",
    "#         oracle = get_oracle(merge_node_ids, sol, gt_graph, sol_ims, gt_ims)\n",
    "#         oracles[key] = oracle\n",
    "#     else:\n",
    "#         print(f\"Skipping oracle for {key}\")\n",
    "#         oracles[key] = None\n",
    "#     with open(oracle_pth, 'w') as f:\n",
    "#         json.dump(oracles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/oracles.json', 'r') as f:\n",
    "    oracles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_oracle_keys = [key for key in oracles if oracles[key] is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in actual_oracle_keys:\n",
    "    oracle = oracles[key]\n",
    "    introduce_vs = [oracle[key] for key in oracle if oracle[key]['decision'] == 'introduce']\n",
    "    print(merges[key]['n_merges'], len(introduce_vs))\n",
    "    print(introduce_vs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
