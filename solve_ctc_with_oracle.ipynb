{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmvc_metrics import load_sol\n",
    "from ctc_timings import get_im_centers, get_graph\n",
    "from oracle import get_oracle, get_gt_graph\n",
    "from tqdm import tqdm\n",
    "from traccuracy.loaders import load_ctc_data\n",
    "from visualize_lp_solution import load_tiff_frames\n",
    "\n",
    "import json\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_DIR = '/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_summary_df = pd.read_csv('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/ds_summary.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/ctc_metrics.json', 'r') as f:\n",
    "    metric_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_ds_names = []\n",
    "# used_seqs = []\n",
    "# n_frames = []\n",
    "# im_dim = []\n",
    "# min_cells = []\n",
    "# max_cells = []\n",
    "# load_times = []\n",
    "\n",
    "# for i, row in tqdm(enumerate(ds_summary_df.itertuples(), 1), desc='Building & Solving'):\n",
    "#     ds_name = row.ds_name\n",
    "#     seq = '{0:02}'.format(row.seq)\n",
    "#     min_t = 0\n",
    "#     max_t = row.n_frames - 1\n",
    "#     corners = [(0, 0), eval(row.im_dim)]\n",
    "#     key = f'{ds_name}_{row.seq}'\n",
    "#     if isinstance(metric_info[key], dict):\n",
    "#         print(f\"Skipping {key}. Already computed metrics.\")\n",
    "#         continue\n",
    "    \n",
    "#     csv_pth = os.path.join(ROOT_DATA_DIR, f'{ds_name}_{seq}_coords.csv')\n",
    "#     seg_pth = os.path.join(os.path.join(ROOT_DATA_DIR, ds_name), f'{seq}_ST/SEG/')\n",
    "#     start_t = time.time()\n",
    "#     coords, min_t, max_t, corners = get_im_centers(seg_pth)\n",
    "#     duration = time.time() - start_t\n",
    "\n",
    "#     used_ds_names.append(ds_name)\n",
    "#     used_seqs.append(seq)        \n",
    "#     n_frames.append(max_t - min_t + 1)\n",
    "#     im_dim.append(corners[1])\n",
    "#     n_cells_per_frame = coords.groupby('t').size()\n",
    "#     min_cells.append(n_cells_per_frame.min())\n",
    "#     max_cells.append(n_cells_per_frame.max())\n",
    "#     load_times.append(duration)\n",
    "#     coords.to_csv(csv_pth)\n",
    "\n",
    "# ds_summary_df = pd.DataFrame({\n",
    "#     'ds_name': ds_names,\n",
    "#     'seq': seqs,\n",
    "#     'n_frames': n_frames,\n",
    "#     'im_dim': im_dim,\n",
    "#     'min_cells': min_cells,\n",
    "#     'max_cells': max_cells,\n",
    "#     'load_time': load_times\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(used_ds_names)):\n",
    "#     name = used_ds_names[i]\n",
    "#     seq = used_seqs[i]\n",
    "#     row_idx = ds_summary_df[(ds_summary_df.ds_name == name) & (ds_summary_df.seq == int(seq))].index[0]\n",
    "#     ds_summary_df.at[row_idx,'load_time']=load_times[i]\n",
    "#     ds_summary_df.at[row_idx, 'min_cells'] = min_cells[i]\n",
    "#     ds_summary_df.at[row_idx, 'max_cells'] = max_cells[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_summary_df.to_csv('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/ds_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and solve model for each sequence, starting with the smallest in number of frames\n",
    "# ds_summary_df = ds_summary_df.sort_values(by='n_frames')\n",
    "# ds_names_used = []\n",
    "# ds_seqs_used = []\n",
    "# build_times = []\n",
    "# solve_times = []\n",
    "# store_times = []\n",
    "# for i, row in tqdm(enumerate(ds_summary_df.itertuples(), 1), desc='Building & Solving'):\n",
    "#     ds_name = row.ds_name\n",
    "#     seq = row.seq\n",
    "#     min_t = 0\n",
    "#     max_t = row.n_frames - 1\n",
    "#     corners = [(0, 0), eval(row.im_dim)]\n",
    "#     key = f'{ds_name}_{seq}'\n",
    "#     if isinstance(metric_info[key], dict):\n",
    "#         print(f\"Skipping {key}. Already computed metrics.\")\n",
    "#         continue\n",
    "\n",
    "#     print(f\"Re-solving {key}.\")\n",
    "#     ds_seqs_used.append(seq)\n",
    "#     ds_names_used.append(ds_name)\n",
    "    \n",
    "#     sol_dir = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_RES/'.format(seq))\n",
    "#     os.makedirs(sol_dir, exist_ok=True)\n",
    "#     sol_pth = os.path.join(sol_dir, 'full_solution.graphml')\n",
    "\n",
    "#     # read coords\n",
    "#     coords_path = os.path.join(ROOT_DATA_DIR, '{0}_{1:02}_coords.csv'.format(ds_name, seq))\n",
    "#     coords = pd.read_csv(coords_path)\n",
    "    \n",
    "#     # build graph\n",
    "#     graph, build_time = get_graph(coords, min_t, max_t, corners)\n",
    "#     build_times.append(build_time)\n",
    "\n",
    "#     # solve model\n",
    "#     m, flow = graph._to_gurobi_model()\n",
    "#     m.Params.LogToConsole = 0\n",
    "#     m.optimize()\n",
    "#     if m.Status == 3:\n",
    "#         infinite_cost_edges = graph._g.es.select(cost_ge=1e10)\n",
    "#         graph._g.delete_edges(infinite_cost_edges)\n",
    "#         m, flow = graph._to_gurobi_model()\n",
    "#         m.optimize()\n",
    "#         if m.Status != 2:\n",
    "#             raise ValueError(f\"Attempted to remove infinite cost edges but model for {key} was still not solved.\")\n",
    "#     solve_times.append(m.Runtime)\n",
    "    \n",
    "#     # store on graph\n",
    "#     store_time = graph.store_solution(m)\n",
    "#     store_times.append(store_time)\n",
    "    \n",
    "#     # save solution graph\n",
    "#     nx_g = graph.convert_sol_igraph_to_nx()\n",
    "#     nx.write_graphml_lxml(nx_g, sol_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(ds_names_used)):\n",
    "#     name = ds_names_used[i]\n",
    "#     seq = ds_seqs_used[i]\n",
    "#     row_idx = ds_summary_df[(ds_summary_df.ds_name == name) & (ds_summary_df.seq == int(seq))].index[0]\n",
    "#     ds_summary_df.at[row_idx,'build_time']= build_times[i]\n",
    "#     ds_summary_df.at[row_idx, 'solve_time'] = solve_times[i]\n",
    "#     ds_summary_df.at[row_idx, 'store_time'] = store_times[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_summary_df.to_csv('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/ds_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges = {}\n",
    "# for i, row in enumerate(ds_summary_df.itertuples(), 1):\n",
    "#     ds_name = row.ds_name\n",
    "#     seq = row.seq\n",
    "#     merges[f'{ds_name}_{seq}'] = {}\n",
    "    \n",
    "#     sol_dir = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_RES/'.format(seq))\n",
    "#     sol_pth = os.path.join(sol_dir, 'full_solution.graphml')\n",
    "#     seg_pth = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_ST/SEG/'.format(seq))\n",
    "#     gt_pth = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_GT/TRA/'.format(seq))\n",
    "    \n",
    "#     # load solution, check the number of merges\n",
    "#     if not os.path.exists(sol_pth):\n",
    "#         merges[f'{ds_name}_{seq}']['n_merges'] = -1\n",
    "#         merges[f'{ds_name}_{seq}']['merge_nodes'] = []\n",
    "#     else:\n",
    "#         sol_data = load_sol(sol_pth, seg_pth)\n",
    "#         sol = sol_data.tracking_graph.graph\n",
    "#         oracle_node_df = pd.DataFrame.from_dict(sol.nodes, orient='index')\n",
    "        \n",
    "#         merge_nodes = [node for node in sol.nodes if len(sol.in_edges(node)) > 1]\n",
    "#         merges[f'{ds_name}_{seq}']['n_merges'] = len(merge_nodes)\n",
    "#         merges[f'{ds_name}_{seq}']['merge_nodes'] = merge_nodes\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/merge_info.json', 'r') as f:\n",
    "    merges = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oracles = {}\n",
    "# ds_summary_df = ds_summary_df.sort_values(by='n_frames')\n",
    "# oracle_pth = '/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/oracles.json'\n",
    "# for i, row in enumerate(ds_summary_df.itertuples(), 1):\n",
    "#     ds_name = row.ds_name\n",
    "#     seq = row.seq\n",
    "#     key = f'{ds_name}_{seq}'\n",
    "\n",
    "#     sol_dir = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_RES/'.format(seq))\n",
    "#     sol_pth = os.path.join(sol_dir, 'full_solution.graphml')\n",
    "#     seg_pth = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_ST/SEG/'.format(seq))\n",
    "#     gt_pth = os.path.join(ROOT_DATA_DIR, ds_name, '{0:02}_GT/TRA/'.format(seq))\n",
    "\n",
    "#     if merges[key]['n_merges'] and \\\n",
    "#         metric_info[key] is not None and \\\n",
    "#             metric_info[key]['DET'] < 1:\n",
    "#         print(f\"Running oracle for {key}\")\n",
    "#         sol_data = load_sol(sol_pth, seg_pth)\n",
    "#         sol = sol_data.tracking_graph.graph\n",
    "#         sol_ims = sol_data.segmentation\n",
    "        \n",
    "#         oracle_node_df = pd.DataFrame.from_dict(sol.nodes, orient='index')\n",
    "#         merge_node_ids = merges[key]['merge_nodes']\n",
    "#         gt_data = load_ctc_data(gt_pth)\n",
    "#         gt_graph = gt_data.tracking_graph.graph\n",
    "#         gt_ims = gt_data.segmentation\n",
    "        \n",
    "#         oracle = get_oracle(merge_node_ids, sol, gt_graph, sol_ims, gt_ims)\n",
    "#         oracles[key] = oracle\n",
    "#     else:\n",
    "#         print(f\"Skipping oracle for {key}\")\n",
    "#         oracles[key] = None\n",
    "#     with open(oracle_pth, 'w') as f:\n",
    "#         json.dump(oracles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/draga/PhD/data/cell_tracking_challenge/ST_Segmentations/oracles.json', 'r') as f:\n",
    "    oracles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_oracle_keys = [key for key in oracles if oracles[key] is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in actual_oracle_keys:\n",
    "    oracle = oracles[key]\n",
    "    introduce_vs = [oracle[key] for key in oracle if oracle[key]['decision'] == 'introduce']\n",
    "    print(merges[key]['n_merges'], len(introduce_vs))\n",
    "    print(introduce_vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
