{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from ctc_timings import get_im_centers, get_graph\n",
    "from visualize_lp_solution import load_tiff_frames\n",
    "import networkx as nx\n",
    "import igraph\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/draga/PhD/data/cell_tracking_challenge/'\n",
    "OUT_ROOT = '/home/draga/PhD/code/experiments/ctc/'\n",
    "DS_NAME = 'Fluo-N2DL-HeLa/'\n",
    "SEQ = '01_ST'\n",
    "MIGRATION_ONLY = False\n",
    "GT_PATH = os.path.join(\"/home/draga/PhD/data/cell_tracking_challenge/\", DS_NAME, '01_GT/TRA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Solve Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = os.path.join(DATA_ROOT, DS_NAME, SEQ, 'TRA/' if SEQ.endswith('GT') else 'SEG/')\n",
    "model_root = os.path.join(OUT_ROOT, DS_NAME, SEQ, 'models/')\n",
    "sol_root = os.path.join(OUT_ROOT, DS_NAME, SEQ, 'output/')\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "os.makedirs(sol_root, exist_ok=True)\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%d%b%y_%H%M\")\n",
    "out_path = os.path.join(OUT_ROOT, DS_NAME, SEQ, f'runtimes.csv')\n",
    "model_path = os.path.join(model_root, f'{current_datetime}.lp')\n",
    "sol_path = os.path.join(sol_root, f'{current_datetime}.sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building kD trees: 100%|██████████| 92/92 [00:01<00:00, 54.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing appearance/exit costs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making appearance/exit edges: 100%|██████████| 8602/8602 [00:00<00:00, 60907.18it/s]\n",
      "Making migration & division edges: 100%|██████████| 91/91 [00:12<00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build duration:  14.503974676132202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "coords, min_t, max_t, corners = get_im_centers(im_dir)\n",
    "graph, build_time = get_graph(coords, min_t, max_t, corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-05-12\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 25809 rows, 110332 columns and 424120 nonzeros\n",
      "Model fingerprint: 0xfa47d5f2\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-02, 4e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "\n",
      "Concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Presolve removed 139 rows and 2 columns\n",
      "Presolve time: 0.54s\n",
      "Presolved: 25670 rows, 110330 columns, 422622 nonzeros\n",
      "\n",
      "Ordering time: 0.07s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 3.038e+05\n",
      " Factor NZ  : 1.262e+06 (roughly 70 MB of memory)\n",
      " Factor Ops : 1.681e+08 (less than 1 second per iteration)\n",
      " Threads    : 3\n",
      "\n",
      "Barrier performed 0 iterations in 0.84 seconds (0.27 work units)\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "\n",
      "Solved with dual simplex\n",
      "Solved in 9565 iterations and 0.85 seconds (0.33 work units)\n",
      "Optimal objective  3.163712733e+04\n"
     ]
    }
   ],
   "source": [
    "m, flow = graph._to_gurobi_model()\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_solution_on_graph(opt_model, graph):\n",
    "    sol_vars = opt_model.getVars()\n",
    "    v_info = [v.VarName.lstrip('flow[').rstrip(']').split(',') + [v.X] for v in sol_vars]\n",
    "    v_dict = {int(eid): {\n",
    "        'var_name': var_name,\n",
    "        'src_id': int(src_id),\n",
    "        'target_id': int(target_id),\n",
    "        'flow': float(flow)\n",
    "    } for eid, var_name, src_id, src_label, target_id, target_label, flow in v_info if float(flow) > 0}\n",
    "\n",
    "    # store the correct flow on each graph edge\n",
    "    graph._g.es['flow'] = 0\n",
    "    graph._g.es.select(list(v_dict.keys()))['flow'] = [v_dict[eid]['flow'] for eid in v_dict.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v long step can we avoid or make faster\n",
    "store_solution_on_graph(m, graph)\n",
    "graph.save_flow_info(coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle\n",
    "\n",
    "The first step in creating an oracle is finding the correct \"context\" i.e. groups of vertices and edges in the ground truth that correspond to a given problem vertex `v` in the solution.\n",
    "\n",
    "This is a reincarnation of the graph matching problem for benchmarking against ground truth solutions. \n",
    "\n",
    "Requirements given a sol vertex `v`:\n",
    "\n",
    "- find associated vertices in ground truth\n",
    "  - could be many especially for a split\n",
    "- don't pick up any unassociated vertices (because these might be other vertices in our own graph)\n",
    "\n",
    "Given that merge vertices have typically been an instance of undersegmentation, we pick all vertices in GT whose bounding boxes overlap with `v` in the solution.\n",
    "\n",
    "**NOTE** the proportion of overlap could be its own parameter in an interactive system\n",
    "\n",
    "**Also Note**: We can't use the exact same matching as in the metrics computation... can we?\n",
    "- Because of majority overlap requirement, even if a computed vertex overlaps \"a good chunk\" of a ground truth vertex, it won't be matched - we'd like to find all of these overlapped vertices - but what if two computed vertices overlap the same ground truth vertex? Why don't we just look for nearby vertices in the false negatives or non splits of the existing match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/draga/miniconda3/envs/napari-graph/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/tmp/ipykernel_9095/1176450289.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  parent_coords = coords[(coords.label == parent_id)][coords.t == parent_end_t]\n"
     ]
    }
   ],
   "source": [
    "# load GT graph\n",
    "def get_gt_graph(gt_path):\n",
    "    coords, min_t, max_t, corners = get_im_centers(GT_PATH)\n",
    "    srcs = []\n",
    "    dests = []\n",
    "    is_parent = []\n",
    "    for label_val in range(coords['label'].min(), coords['label'].max()):\n",
    "        gt_points = coords[coords.label == label_val].sort_values(by='t')\n",
    "        track_edges = [(gt_points.index.values[i], gt_points.index.values[i+1]) for i in range(0, len(gt_points)-1)]\n",
    "        if len(track_edges):\n",
    "            sources, targets = zip(*track_edges)\n",
    "            srcs.extend(sources)\n",
    "            dests.extend(targets)\n",
    "            is_parent.extend([0 for _ in range(len(sources))])\n",
    "\n",
    "    man_track = pd.read_csv(os.path.join(gt_path, 'man_track.txt'), sep=' ', header=None)\n",
    "    man_track.columns = ['current', 'start_t', 'end_t', 'parent']\n",
    "    child_tracks = man_track[man_track.parent != 0]\n",
    "    for index, row in child_tracks.iterrows():\n",
    "        parent_id = row['parent']\n",
    "        parent_end_t = man_track[man_track.current == parent_id]['end_t'].values[0]\n",
    "        parent_coords = coords[(coords.label == parent_id)][coords.t == parent_end_t]\n",
    "        child_coords = coords[(coords.label == row['current']) & (coords.t == row['start_t'])]\n",
    "        srcs.append(parent_coords.index.values[0])\n",
    "        dests.append(child_coords.index.values[0])\n",
    "        is_parent.append(1)\n",
    "\n",
    "    edges = pd.DataFrame({\n",
    "        'sources': srcs,\n",
    "        'dests': dests,\n",
    "        'is_parent': is_parent\n",
    "    })    \n",
    "    graph = igraph.Graph.DataFrame(edges, directed=True, vertices=coords, use_vids=True)\n",
    "    return graph, coords\n",
    "\n",
    "gt_graph, gt_coords = get_gt_graph(GT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gt_ims\n",
    "sol_ims = load_tiff_frames(im_dir)\n",
    "gt_ims = load_tiff_frames(GT_PATH)\n",
    "merge_rows = coords[coords['in-mig'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching vertices with bounding box overlap\n",
    "def get_gt_match_vertices(coords, gt_coords, sol_ims, gt_ims, v_id):\n",
    "    from traccuracy.matchers._compute_overlap import get_labels_with_overlap\n",
    "\n",
    "    # get mask of problem blob\n",
    "    problem_info = coords.loc[[v_id], ['label', 't']]\n",
    "    problem_label = problem_info['label'].values[0]\n",
    "    problem_t = problem_info['t'].values[0]\n",
    "    if (ct := len(problem_info)) > 1:\n",
    "        raise ValueError(f\"Solution label {problem_label} appears {ct} times in frame {problem_t}.\")\n",
    "    mask = sol_ims[problem_t] == problem_label\n",
    "    gt_frame = gt_ims[problem_t]\n",
    "    gt_ov_labels, _ = get_labels_with_overlap(gt_frame, mask)\n",
    "    gt_v_ids = []\n",
    "    for label in gt_ov_labels:\n",
    "        row = gt_coords[(gt_coords.label == label) & (gt_coords.t==problem_t)]\n",
    "        if (ct := len(row)) > 1:\n",
    "            raise ValueError(f\"GT label {label} appears {ct} times in frame {problem_t}.\")\n",
    "        vid = row.index.values[0]\n",
    "        gt_v_ids.append(vid)\n",
    "    return gt_v_ids\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a merge on vertex `v` is a result of undersegmentation, we expect to be able to find two (or potentially more) GT vertices with bounding boxes overlapping `v` - the one matching `v` itself, and the one matching the unidentified cell. \n",
    "\n",
    "Below we check the overlapping GT vertices for each merge vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_no_match = 0\n",
    "count_single_match = 0\n",
    "count_multi_match = 0\n",
    "for i, _ in merge_rows.iterrows():\n",
    "    gt_matched = get_gt_match_vertices(coords, gt_coords, sol_ims, gt_ims, i)\n",
    "    print(f'Matching GT vertices for {i}: {gt_matched}')\n",
    "    ct = len(gt_matched)\n",
    "    if ct == 0:\n",
    "        count_no_match += 1\n",
    "    elif ct == 1:\n",
    "        count_single_match += 1\n",
    "    else:\n",
    "        count_multi_match += 1\n",
    "print(f\"Unmatched: {count_no_match}\\nMatched: {count_single_match}\\nMulti-matched: {count_multi_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have matched every vertex (meaning we can be confident the merge vertices are real vertices in the ground truth graph), but only one of the merge vertices has an additional overlapping vertex i.e. was undersegmented by this overlap measure.\n",
    "\n",
    "So, we need to be a bit less strict with our matching criteria, and match GT vertices within a given tolerance of the merge vertex. Keeping in mind we are trying not to make false associations for unrelated vertices in our solution, we can limit this approximate match to only **GT vertices within a given distance of `v` that have no other matching vertices in the solution graph** - these are false negative vertices which, if added to the solution, cannot possibly be a mis-association of an existing vertex.\n",
    "\n",
    "**NOTE** We should probably **only** be doing this. If multiple computed vertices overlap the same gt vertex, how would we one identify that and two decide among them - of course in this check we dismiss a reference vertex if they have **any** overlap, so I think we're actually still running into this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertices in gt frame near to v's parents that don't have matching vertices in solution\n",
    "def get_gt_unmatched_vertices(coords, gt_coords, sol_ims, gt_ims, v_id, dist):\n",
    "    from scipy.spatial import KDTree\n",
    "    from traccuracy.matchers._compute_overlap import get_labels_with_overlap\n",
    "    import numpy as np\n",
    "\n",
    "    problem_row = coords.loc[[v_id]]\n",
    "    problem_t = problem_row['t'].values[0]\n",
    "    cols = ['y', 'x']\n",
    "    if 'z' in coords.columns:\n",
    "        cols = ['z', 'y', 'x']\n",
    "    problem_coords = tuple(problem_row[cols].values[0])\n",
    "    \n",
    "    # build kdt from gt frame\n",
    "    gt_frame_coords = gt_coords[gt_coords['t'] == problem_t][cols]\n",
    "    coord_indices, *coord_tuples = zip(*list(gt_frame_coords.itertuples(name=None)))\n",
    "    coord_tuples = np.asarray(list(zip(*coord_tuples)))\n",
    "    coord_indices = np.asarray(coord_indices)\n",
    "\n",
    "    # get nearby vertices\n",
    "    gt_tree = KDTree(coord_tuples)\n",
    "    potential_unmatched = coord_indices[gt_tree.query_ball_point(problem_coords, dist, return_sorted=True)]\n",
    "    \n",
    "    unmatched = []\n",
    "    problem_frame = sol_ims[problem_t]\n",
    "    # check if they don't overlap with any solution vertices i.e. they are a fn\n",
    "    for v in potential_unmatched:\n",
    "        v_label = gt_coords.loc[[v], ['label']].values[0]\n",
    "        mask = gt_ims[problem_t] == v_label\n",
    "        _, sol_overlaps = get_labels_with_overlap(mask, problem_frame)\n",
    "        if not len(sol_overlaps):\n",
    "            unmatched.append(v)\n",
    "    return unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_unmatched_vertices_near_parent(coords, gt_coords, sol_ims, gt_ims, v_id, v_parents, dist):\n",
    "    from scipy.spatial import KDTree\n",
    "    from traccuracy.matchers._compute_overlap import get_labels_with_overlap\n",
    "    import numpy as np\n",
    "\n",
    "    problem_row = coords.loc[[v_id]]\n",
    "    problem_t = problem_row['t'].values[0]\n",
    "    cols = ['y', 'x']\n",
    "    if 'z' in coords.columns:\n",
    "        cols = ['z', 'y', 'x']\n",
    "    parent_rows = coords.loc[v_parents]\n",
    "    parent_coords = parent_rows[cols].values\n",
    "    \n",
    "    # build kdt from gt frame\n",
    "    gt_frame_coords = gt_coords[gt_coords['t'] == problem_t][cols]\n",
    "    coord_indices, *coord_tuples = zip(*list(gt_frame_coords.itertuples(name=None)))\n",
    "    coord_tuples = np.asarray(list(zip(*coord_tuples)))\n",
    "    coord_indices = np.asarray(coord_indices)\n",
    "\n",
    "    # get nearby vertices close to both parents of v\n",
    "\n",
    "    gt_tree = KDTree(coord_tuples)\n",
    "    nearby = [n_index for n_list in gt_tree.query_ball_point(parent_coords, dist, return_sorted=True) for n_index in n_list]\n",
    "    potential_unmatched = coord_indices[nearby]\n",
    "    unmatched = []\n",
    "    problem_frame = sol_ims[problem_t]\n",
    "    # check if they don't overlap with any solution vertices i.e. they are a fn\n",
    "    for v in potential_unmatched:\n",
    "        v_label = gt_coords.loc[[v], ['label']].values[0]\n",
    "        mask = gt_ims[problem_t] == v_label\n",
    "        _, sol_overlaps = get_labels_with_overlap(mask, problem_frame)\n",
    "        if not len(sol_overlaps) and v not in unmatched:\n",
    "            unmatched.append(v)\n",
    "    return unmatched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we check whether unmatched GT vertices exist for the merge vertices above for different distance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_none = []\n",
    "counts_one = []\n",
    "counts_multi = []\n",
    "dists = [10, 20, 25, 30, 35, 40, 50, 60, 70]\n",
    "for dist in dists:\n",
    "    count_no_unmatched = 0\n",
    "    count_one_unmatched = 0\n",
    "    count_multi_unmatched = 0\n",
    "    for i, _ in merge_rows.iterrows():\n",
    "        parent_ids = [v for v in graph._g.neighbors(i, mode='in') if graph._g.es[graph._g.get_eid(v, i)]['flow'] > 0]\n",
    "        unmatched_gt = get_gt_unmatched_vertices_near_parent(coords, gt_coords, sol_ims, gt_ims, i, parent_ids, dist)\n",
    "        ct = len(unmatched_gt)\n",
    "        if ct == 0:\n",
    "            count_no_unmatched += 1\n",
    "        elif ct == 1:\n",
    "            count_one_unmatched += 1\n",
    "        else:\n",
    "            count_multi_unmatched += 1\n",
    "            # print(f\"At distance {dist}, unmatched GT near {i}: {unmatched_gt}\")\n",
    "    counts_none.append(count_no_unmatched)\n",
    "    counts_one.append(count_one_unmatched)\n",
    "    counts_multi.append(count_multi_unmatched)\n",
    "for i, dist in enumerate(dists):\n",
    "    print(f\"Distance: {dist}\\nNone: {counts_none[i]}, One: {counts_one[i]}, Multi: {counts_multi[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the quick exploration above it looks like for this dataset, a distance of 40px captures many close-by unmatched vertices without finding multiple for a given vertex - which is more likely to be an unrelated vertex. Given the two functions above, let's see how many merge vertices have >1 associated GT vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_no_match = 0\n",
    "count_single_match = 0\n",
    "count_multi_match = 0\n",
    "for i, _ in merge_rows.iterrows():\n",
    "    gt_matched = get_gt_match_vertices(coords, gt_coords, sol_ims, gt_ims, i)\n",
    "    # print(f'Matching GT vertices for {i}: {gt_matched}')\n",
    "    if len(gt_matched) == 1:\n",
    "        parent_ids = [v for v in graph._g.neighbors(i, mode='in') if graph._g.es[graph._g.get_eid(v, i)]['flow'] > 0]\n",
    "        gt_unmatched = get_gt_unmatched_vertices_near_parent(coords, gt_coords, sol_ims, gt_ims, i, parent_ids, 50)\n",
    "    else:\n",
    "        gt_unmatched = []\n",
    "    # print(f'Unmatched GT vertices for {i}: {gt_unmatched}')\n",
    "    ct = len(gt_matched) + len(gt_unmatched)\n",
    "    if ct == 0:\n",
    "        count_no_match += 1\n",
    "    elif ct == 1:\n",
    "        count_single_match += 1\n",
    "    else:\n",
    "        count_multi_match += 1\n",
    "print(f\"Unmatched: {count_no_match}\\nMatched: {count_single_match}\\nMulti-matched: {count_multi_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Vertices\n",
    "\n",
    "As we can see, after using the more relaxed matching measure when only one overlapping GT vertex is found, we find two associated vertices for half of the merge vertices, and a single vertex for the rest. Now we need to decide what to do with them.\n",
    "\n",
    "Merge vertices **must** split on the next frame and this occurs in two (currently observed) ways in the dataset:\n",
    "\n",
    "- A cell is undersegmented for a single frame, and the merge divides into its two constituents on the next frame\n",
    "- A cell is undersegmented for multiple frames, and the extra flow in the merge vertex is shunted to a cell that divides in the next frame\n",
    "  - which **should** be division flow\n",
    "\n",
    "For now, we make minimal changes by simply introducing the additional vertices and fixing their incoming and outgoing edges. Introduced vertex `v'` is matched to `v`s furthest parent. Outgoing edges are slightly more complex.\n",
    "\n",
    "When neither of `v`s current children are merge vertices, we connect `v` to its closest child, and `v'` to the other child. When a next vertex **is** a merge vertex, it means frame `t+1` does not contain a reasonable split for `v`, and the flow was sent elsewhere to cope. As a result, we terminate `v`s predecessor `u` with the longest edge to `v` i.e. `u` flows to target - this \"divests\" it of any additional flow. We also do this with `v`s furthest away parent if there is no additional vertex introduced - implying there is no reasonable split available for `v` at time `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_label = 0\n",
    "last_index = 0\n",
    "v_info = None\n",
    "oracle = {}\n",
    "for i, _ in merge_rows.iterrows():\n",
    "    gt_matched = get_gt_match_vertices(coords, gt_coords, sol_ims, gt_ims, i)\n",
    "    parent_ids = [v for v in graph._g.neighbors(i, mode='in') if graph._g.es[graph._g.get_eid(v, i)]['flow'] > 0]\n",
    "    gt_unmatched = get_gt_unmatched_vertices_near_parent(coords, gt_coords, sol_ims, gt_ims, i, parent_ids, 50)\n",
    "    problem_v = coords.loc[[i]]\n",
    "    problem_coords = tuple(problem_v[['y', 'x']].values[0])\n",
    "\n",
    "    # we couldn't find a match for this vertex at all, we should just delete it\n",
    "    if not len(gt_matched) and not len(gt_unmatched):\n",
    "        decision = 'delete'\n",
    "    # we've only found one vertex nearby, it's v itself\n",
    "    elif len(gt_matched) + len(gt_unmatched) == 1:\n",
    "        decision = 'terminate'\n",
    "    # more than one \"true\" vertex overlaps v, a vertex should be introduced\n",
    "    elif len(gt_matched) > 1:\n",
    "        # closest match is `v`, second closest gets introduced\n",
    "        distances_to_v = [np.linalg.norm(\n",
    "                            np.asarray(problem_coords) - np.asarray(gt_coords.loc[[v], ['y', 'x']].values[0])\n",
    "                        ) for v in gt_matched]\n",
    "        second_closest = gt_matched[np.argsort(distances_to_v)[1]]\n",
    "        v_info = gt_coords.loc[second_closest]\n",
    "        decision = 'introduce'\n",
    "    # we didn't find >1 overlap, but we've found an unmatched GT vertex nearby\n",
    "    elif len(gt_unmatched):\n",
    "        # we just take the closest\n",
    "        v_id = gt_unmatched[0]\n",
    "        v_info = gt_coords.loc[v_id]\n",
    "        decision = 'introduce'\n",
    "\n",
    "    if v_info is not None:\n",
    "        if last_label == 0:\n",
    "            next_label = coords['label'].max() + 1\n",
    "            # hypervertices...\n",
    "            new_index = max(coords.index.values) + 5\n",
    "        else:\n",
    "            next_label = last_label + 1\n",
    "            new_index = last_index + 1\n",
    "\n",
    "        last_label = next_label\n",
    "        last_index = new_index\n",
    "\n",
    "    oracle[i] = {\n",
    "        'decision': decision,\n",
    "        'v_info': None if v_info is None else (new_index, list(v_info[['t', 'y', 'x']]) + [next_label]),\n",
    "        'parent': None\n",
    "    }\n",
    "    v_info = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing just vertices - no edge fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduce_vertices = dict(filter(lambda item: item[1]['decision'] == 'introduce', oracle.items()))\n",
    "introduce_oracle = {item['v_info'][0]: (int(item['v_info'][1][0]), item['v_info'][1][1:-1], item['v_info'][1][-1]) for item in introduce_vertices.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_ts = set()\n",
    "for new_vid, v_info in introduce_oracle.items():\n",
    "    t, coords, new_label = v_info\n",
    "    affected_ts.add(t)\n",
    "affected_ts = list(sorted(affected_ts))\n",
    "for i, t in enumerate(affected_ts):\n",
    "    if not i:\n",
    "        pairs = [(t-1, t), (t, t+1)]\n",
    "    elif t - affected_ts[i-1] > 1:\n",
    "        pairs = [(t-1, t), (t, t+1)]\n",
    "    else:\n",
    "        pairs = [(t, t+1)]\n",
    "    print(f't: {t}, pairs: {pairs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing vertices and fixing edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_vertex(merge_v, graph, oracle):\n",
    "    oracle_info = oracle[merge_v]\n",
    "    new_vid, info = oracle_info['v_info']\n",
    "    t = int(info[0])\n",
    "    coords = tuple(info[1:3])\n",
    "    new_label = info[3]\n",
    "\n",
    "    get_flow = lambda x, y: graph._g.es[graph._g.get_eid(x, y)]['flow']\n",
    "    get_distance = lambda x, y: np.linalg.norm(np.asarray(x['coords'])) - np.linalg.norm(np.asarray(y['coords']))\n",
    "\n",
    "    children = [graph._g.vs[v] for v in graph._g.neighbors(merge_v, 'out') if get_flow(merge_v, v) > 0]\n",
    "\n",
    "    parents = [graph._g.vs[v] for v in graph._g.neighbors(merge_v, 'in') if get_flow(v, merge_v) > 0]\n",
    "    # merge_v has been dealt with, it might have a new parent to assign\n",
    "    if len(parents) < 2:\n",
    "        if oracle[merge_v]['parent']:\n",
    "            new_parent = oracle[merge_v]['parent']\n",
    "        # if it doesn't that means there's a vertex being introduced, but we don't know who to parent it to?\n",
    "        else:\n",
    "            new_parent = None\n",
    "            raise ValueError(f\"Vertex {merge_v} only has parents {parents}. New vertex {new_vid}:{v_info} will have no parent connnection!\")\n",
    "    else:\n",
    "        new_parent = parents[0].index if get_distance(parents[0], graph._g.vs[merge_v]) > get_distance(parents[1], graph._g.vs[merge_v]) else parents[1].index\n",
    "\n",
    "    # add vertex\n",
    "    graph.introduce_vertex(new_vid, t, coords, new_label)\n",
    "    if graph._g.are_connected(new_parent, merge_v):\n",
    "        # delete current edge (new_parent, merge_v)\n",
    "        graph._g.delete_edges([(new_parent,merge_v)])\n",
    "    # add new edge (new_parent, introduced_v)\n",
    "    graph.add_edge(new_parent, new_vid, is_fixed=True)\n",
    "\n",
    "    is_merge_child1 = children[0].index  in oracle\n",
    "    is_merge_child2 = children[1].index  in oracle\n",
    "    # find longest edge\n",
    "    furthest_child = children[0].index if get_distance(graph._g.vs[merge_v], children[0]) > get_distance(graph._g.vs[merge_v], children[1]) else children[1].index\n",
    "    # neither child a merge\n",
    "    if not is_merge_child1 and not is_merge_child2:\n",
    "        # delete current edge (merge_v, furthest_child)\n",
    "        graph._g.delete_edges([(merge_v, furthest_child)])\n",
    "        # add new edge (new_v, furthest_child)\n",
    "        graph.add_edge(new_vid, furthest_child, is_fixed=True)\n",
    "    # a single child is merge\n",
    "    elif is_merge_child1 ^ is_merge_child2:\n",
    "        merge_child, other_child = (children[0].index, children[1].index) if is_merge_child1 else (children[1].index, children[0].index)\n",
    "        \n",
    "        # delete current edge (merge_v, merge_child)\n",
    "        graph._g.delete_edges([(merge_v, merge_child)])\n",
    "        # fix edge (merge_v, other_child) - cost =0?\n",
    "        graph._g.es[graph._g.get_eid(merge_v, other_child)]['cost'] = 0\n",
    "\n",
    "        # this merge child will also be getting split, so we'll have a new vertex to parent to new_vid\n",
    "        if oracle[merge_child]['decision'] == 'introduce':\n",
    "            oracle[merge_child]['parent'] = new_vid\n",
    "        # we'll have nowhere really to send this vertex, so send it to target\n",
    "        else:\n",
    "            # add edge (new_v, target)\n",
    "            graph.add_edge(new_vid, graph.target.index, is_fixed=True)\n",
    "    # both children merge\n",
    "    else:\n",
    "        # delete current edges (merge_v, both_children)\n",
    "        graph._g.delete_edges([(merge_v, children[0].index)])\n",
    "        graph._g.delete_edges([(merge_v, children[1].index)])\n",
    "\n",
    "        # add edge new_v - target\n",
    "        graph.add_edge(new_vid, graph.target.index, is_fixed=True)\n",
    "        # add edge merge_v - target\n",
    "        graph.add_edge(new_vid, graph.target.index, is_fixed=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got functions to deal with the decisions made by the oracle, we can apply them on the graph. We save the full graph for visualization purposes, and then build and solve the optimization model again on the updated graph.\n",
    "\n",
    "Because the graph is changing as we introduce/terminate vertices, it's important that our oracle can deal with these changes appropriately. In particular, by the time we get to a certain time frame and introduce a vertex, `v'`, it may no longer be a merge vertex, if its edges have been fixed as part of a previous introduction.\n",
    "\n",
    "To deal with this we first:\n",
    "- Introduce all vertices before terminating any. Introduced vertices are more likely to \"fix\" the local graph, and given our retrieval of them, we can be relatively sure they **need** to be there. Termination is a more fuzzy oracle decision, so we only make it if we really have to.\n",
    "- When introducing a vertex `v'` at `t` whose associated merge vertex `v` is no longer a merge vertex, it means we must have introduced a vertex in the previous frame - this new vertex should be the parent of `v'`\n",
    "    - We track this new parent in the oracle so that we can appropriately assign it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduce_vertices = dict(filter(lambda item: item[1]['decision'] == 'introduce', oracle.items()))\n",
    "for vid in introduce_vertices:\n",
    "    introduce_vertex(vid, graph, oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still_merged = []\n",
    "# for merge_v in oracle.keys():\n",
    "#     incoming_vs = graph._g.neighbors(merge_v, mode='in')\n",
    "#     actual_incoming = []\n",
    "#     for v in incoming_vs:\n",
    "#         relevant_edge = graph._g.es[graph._g.get_eid(v, merge_v)]\n",
    "#         if relevant_edge['flow'] > 0 or relevant_edge['cost'] == 0:\n",
    "#             actual_incoming.append(v)\n",
    "#     if len(actual_incoming) > 1:\n",
    "#         print(f\"Vertex {merge_v} is still a merge vertex. Incoming vertices: {actual_incoming}\")\n",
    "#         print(f\"Oracle for {merge_v}: {oracle[merge_v]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "# full_path = \"/home/draga/PhD/data/cell_tracking_challenge/Fluo-N2DL-HeLa/01_RES_IC/oracle_introduced_full.graphml\"\n",
    "# del(graph._g.vs['name'])\n",
    "# del(graph._g.es['label'])\n",
    "# for v in graph._g.vs:\n",
    "#     v['y'] = v['coords'][0]\n",
    "#     v['x'] = v['coords'][1]\n",
    "#     for attr_name in graph._g.vertex_attributes():\n",
    "#         if isinstance(v[attr_name], np.bool_):\n",
    "#             v[attr_name] = int(v[attr_name])\n",
    "#         elif v[attr_name] is None:\n",
    "#             v[attr_name] = ''\n",
    "# for e in graph._g.es:\n",
    "#     for attr_name in graph._g.edge_attributes():\n",
    "#         if e[attr_name] is None:\n",
    "#             e[attr_name] = 0\n",
    "# del(graph._g.vs['coords'])\n",
    "# g_nx = graph._g.to_networkx()\n",
    "# nx.write_graphml_lxml(g_nx, full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# mig_copy = graph._g.copy()\n",
    "# mig_copy.delete_edges(lambda e: (e['flow'] == 0 and e['cost'] > 0))\n",
    "# to_delete_ids = [v.index for v in mig_copy.vs if v['label'] in ['division', 'source', 'appearance', 'target']]\n",
    "# mig_copy.delete_vertices(to_delete_ids)\n",
    "# mig_nx = mig_copy.to_networkx()\n",
    "# full_path = \"/home/draga/PhD/data/cell_tracking_challenge/Fluo-N2DL-HeLa/01_RES_IC/oracle_introduced_mig.graphml\"\n",
    "# nx.write_graphml_lxml(mig_nx, full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild Model, Solve and Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_m, flow = graph._to_gurobi_model()\n",
    "new_m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sol_igraph_to_nx(graph):\n",
    "    for v in graph._g.vs:\n",
    "        v['y'] = v['coords'][0]\n",
    "        v['x'] = v['coords'][1]\n",
    "        for attr_name in graph._g.vertex_attributes():\n",
    "            if isinstance(v[attr_name], np.bool_):\n",
    "                v[attr_name] = int(v[attr_name])\n",
    "            elif v[attr_name] is None:\n",
    "                v[attr_name] = 0\n",
    "    for e in graph._g.es:\n",
    "        for attr_name in graph._g.edge_attributes():\n",
    "            if e[attr_name] is None:\n",
    "                e[attr_name] = 0\n",
    "    del(graph._g.vs['coords'])\n",
    "    del(graph._g.vs['name'])\n",
    "    del(graph._g.vs['label'])\n",
    "\n",
    "    del(graph._g.es['label'])\n",
    "    nx_g = graph._g.to_networkx()\n",
    "    return nx_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save info on graph\n",
    "store_solution_on_graph(new_m, graph)\n",
    "nx_g = convert_sol_igraph_to_nx(graph)\n",
    "oracle_node_df = pd.DataFrame.from_dict(nx_g.nodes, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.save_flow_info(oracle_node_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = \"/home/draga/PhD/data/cell_tracking_challenge/Fluo-N2DL-HeLa/01_RES_IC/oracle_introduced_mig_near_parent.graphml\"\n",
    "nx.write_graphml_lxml(nx_g, full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_merge_vertex(merge_v, graph):\n",
    "    get_flow = lambda x, y: graph._g.es[graph._g.get_eid(x, y)]['flow']\n",
    "    get_distance = lambda x, y: np.linalg.norm(np.asarray(x['coords'])) - np.linalg.norm(np.asarray(y['coords']))\n",
    "\n",
    "    parents = [graph._g.vs[v] for v in graph._g.neighbors(merge_v, 'in') if get_flow(v, merge_v) > 0]\n",
    "    children = [graph._g.vs[v] for v in graph._g.neighbors(merge_v, 'out') if get_flow(merge_v, v) > 0]\n",
    "\n",
    "    furthest_child = children[0].index if get_distance(graph._g.vs[merge_v], children[0]) > get_distance(graph._g.vs[merge_v], children[1]) else children[1].index\n",
    "    furthest_parent = parents[0].index if get_distance(parents[0], graph._g.vs[merge_v]) > get_distance(parents[1], graph._g.vs[merge_v]) else parents[1].index\n",
    "    \n",
    "    # Delete edge (furthest_parent, merge_v)\n",
    "    graph._g.delete_edges([(furthest_parent, merge_v)])\n",
    "    # Add edge from furthest parent to target\n",
    "    graph.add_edge(furthest_parent, graph.target.index, is_fixed=True)\n",
    "    # Delete (merge_v, furthest_child)\n",
    "    graph._g.delete_edges([(merge_v, furthest_child)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "- ~~Finish introduce_vertex~~\n",
    "- ~~Write terminate_merge_vertex~~\n",
    "- [ ] How do we handle changes to interconnected merge vertices? I.e. making sure it's consistent\n",
    "  - Do any of these actions risk enforcing a potentially unsatisfiable set of edges\n",
    "- ~~Save edited graph after running introduce~~\n",
    "- ~~Save edited graph after running terminate~~\n",
    "- ~~Add code to rebuild and rerun solution~~\n",
    "- [ ] Check edge labels with `None` in them?\n",
    "- [ ] Update coord rows after introducing vertices so we can save flow info\n",
    "- [ ] Visualize/metric/check new solution\n",
    "  - [ ] Potentially fix metric\n",
    "  - [ ] Check original solution fp/tp/fn edges vs. oracle solution fp/tp/fn edges vs. re-solved fp/tp/fn edges\n",
    "- [ ] Make edge deletion fixed 0 flow\n",
    "- [ ] Improve edge deletion/addition to do all at once\n",
    "\n",
    "- [ ] Update live model and re-solve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('napari-graph': conda)",
   "name": "python3913jvsc74a57bd0bc09f98cf869b83bf3a07bdaffe5ae213e0bb152dc8300e4fba8a5fbb22b2b92"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}