{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from ctc_timings import get_im_centers, get_graph\n",
    "from visualize_lp_solution import load_tiff_frames\n",
    "import networkx as nx\n",
    "import igraph\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/draga/PhD/data/cell_tracking_challenge/'\n",
    "OUT_ROOT = '/home/draga/PhD/code/experiments/ctc/'\n",
    "DS_NAME = 'Fluo-N2DL-HeLa/'\n",
    "SEQ = '01_ST'\n",
    "MIGRATION_ONLY = False\n",
    "GT_PATH = os.path.join(\"/home/draga/PhD/data/cell_tracking_challenge/\", DS_NAME, '01_GT/TRA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Solve Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = os.path.join(DATA_ROOT, DS_NAME, SEQ, 'TRA/' if SEQ.endswith('GT') else 'SEG/')\n",
    "model_root = os.path.join(OUT_ROOT, DS_NAME, SEQ, 'models/')\n",
    "sol_root = os.path.join(OUT_ROOT, DS_NAME, SEQ, 'output/')\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "os.makedirs(sol_root, exist_ok=True)\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%d%b%y_%H%M\")\n",
    "out_path = os.path.join(OUT_ROOT, DS_NAME, SEQ, f'runtimes.csv')\n",
    "model_path = os.path.join(model_root, f'{current_datetime}.lp')\n",
    "sol_path = os.path.join(sol_root, f'{current_datetime}.sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building kD trees: 100%|██████████| 92/92 [00:01<00:00, 58.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing appearance/exit costs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making appearance/exit edges: 100%|██████████| 8602/8602 [00:00<00:00, 71669.30it/s]\n",
      "Making migration & division edges:  48%|████▊     | 44/91 [00:03<00:05,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making migration & division edges: 100%|██████████| 91/91 [00:11<00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build duration:  13.20469331741333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "coords, min_t, max_t, corners = get_im_centers(im_dir)\n",
    "graph, build_time = get_graph(coords, min_t, max_t, corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-05-12\n",
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 25809 rows, 110332 columns and 424120 nonzeros\n",
      "Model fingerprint: 0xfa47d5f2\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-02, 4e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "\n",
      "Concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Presolve removed 139 rows and 2 columns\n",
      "Presolve time: 0.62s\n",
      "Presolved: 25670 rows, 110330 columns, 422622 nonzeros\n",
      "\n",
      "Ordering time: 0.07s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 3.038e+05\n",
      " Factor NZ  : 1.262e+06 (roughly 70 MB of memory)\n",
      " Factor Ops : 1.681e+08 (less than 1 second per iteration)\n",
      " Threads    : 3\n",
      "\n",
      "Barrier performed 0 iterations in 1.01 seconds (0.29 work units)\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "\n",
      "Solved with dual simplex\n",
      "Solved in 9565 iterations and 1.03 seconds (0.33 work units)\n",
      "Optimal objective  3.163712733e+04\n"
     ]
    }
   ],
   "source": [
    "m, flow = graph._to_gurobi_model()\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_solution_on_graph(opt_model, graph):\n",
    "    sol_vars = opt_model.getVars()\n",
    "    v_info = [v.VarName.lstrip('flow[').rstrip(']').split(',') + [v.X] for v in sol_vars]\n",
    "    v_dict = {int(eid): {\n",
    "        'var_name': var_name,\n",
    "        'src_id': int(src_id),\n",
    "        'target_id': int(target_id),\n",
    "        'flow': float(flow)\n",
    "    } for eid, var_name, src_id, src_label, target_id, target_label, flow in v_info if float(flow) > 0}\n",
    "\n",
    "    # store the correct flow on each graph edge\n",
    "    graph._g.es['flow'] = 0\n",
    "    graph._g.es.select(list(v_dict.keys()))['flow'] = [v_dict[eid]['flow'] for eid in v_dict.keys()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summing flow: 100%|██████████| 8958/8958 [00:41<00:00, 216.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# v long step can we avoid or make faster\n",
    "store_solution_on_graph(m, graph)\n",
    "graph.save_flow_info(coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle\n",
    "\n",
    "The first step in creating an oracle is finding the correct \"context\" i.e. groups of vertices and edges in the ground truth that correspond to a given problem vertex `v` in the solution.\n",
    "\n",
    "This is a reincarnation of the graph matching problem for benchmarking against ground truth solutions. \n",
    "\n",
    "Requirements given a sol vertex `v`:\n",
    "\n",
    "- find associated vertices in ground truth\n",
    "  - could be many especially for a split\n",
    "- don't pick up any unassociated vertices (because these might be other vertices in our own graph)\n",
    "\n",
    "Given that merge vertices have typically been an instance of undersegmentation, we pick all vertices in GT whose bounding boxes overlap with `v` in the solution.\n",
    "\n",
    "**NOTE** the proportion of overlap could be its own parameter in an interactive system\n",
    "\n",
    "**Also Note**: We can't use the exact same matching as in the metrics computation... can we?\n",
    "- Because of majority overlap requirement, even if a computed vertex overlaps \"a good chunk\" of a ground truth vertex, it won't be matched - we'd like to find all of these overlapped vertices - but what if two computed vertices overlap the same ground truth vertex? Why don't we just look for nearby vertices in the false negatives or non splits of the existing match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/draga/miniconda3/envs/napari-graph/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/tmp/ipykernel_22309/1176450289.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  parent_coords = coords[(coords.label == parent_id)][coords.t == parent_end_t]\n"
     ]
    }
   ],
   "source": [
    "# load GT graph\n",
    "def get_gt_graph(gt_path):\n",
    "    coords, min_t, max_t, corners = get_im_centers(GT_PATH)\n",
    "    srcs = []\n",
    "    dests = []\n",
    "    is_parent = []\n",
    "    for label_val in range(coords['label'].min(), coords['label'].max()):\n",
    "        gt_points = coords[coords.label == label_val].sort_values(by='t')\n",
    "        track_edges = [(gt_points.index.values[i], gt_points.index.values[i+1]) for i in range(0, len(gt_points)-1)]\n",
    "        if len(track_edges):\n",
    "            sources, targets = zip(*track_edges)\n",
    "            srcs.extend(sources)\n",
    "            dests.extend(targets)\n",
    "            is_parent.extend([0 for _ in range(len(sources))])\n",
    "\n",
    "    man_track = pd.read_csv(os.path.join(gt_path, 'man_track.txt'), sep=' ', header=None)\n",
    "    man_track.columns = ['current', 'start_t', 'end_t', 'parent']\n",
    "    child_tracks = man_track[man_track.parent != 0]\n",
    "    for index, row in child_tracks.iterrows():\n",
    "        parent_id = row['parent']\n",
    "        parent_end_t = man_track[man_track.current == parent_id]['end_t'].values[0]\n",
    "        parent_coords = coords[(coords.label == parent_id)][coords.t == parent_end_t]\n",
    "        child_coords = coords[(coords.label == row['current']) & (coords.t == row['start_t'])]\n",
    "        srcs.append(parent_coords.index.values[0])\n",
    "        dests.append(child_coords.index.values[0])\n",
    "        is_parent.append(1)\n",
    "\n",
    "    edges = pd.DataFrame({\n",
    "        'sources': srcs,\n",
    "        'dests': dests,\n",
    "        'is_parent': is_parent\n",
    "    })    \n",
    "    graph = igraph.Graph.DataFrame(edges, directed=True, vertices=coords, use_vids=True)\n",
    "    return graph, coords\n",
    "\n",
    "gt_graph, gt_coords = get_gt_graph(GT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gt_ims\n",
    "sol_ims = load_tiff_frames(im_dir)\n",
    "gt_ims = load_tiff_frames(GT_PATH)\n",
    "merge_rows = coords[coords['in-mig'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching vertices with bounding box overlap\n",
    "def get_gt_match_vertices(coords, gt_coords, sol_ims, gt_ims, v_id, label_key='label'):\n",
    "    from traccuracy.matchers._compute_overlap import get_labels_with_overlap\n",
    "\n",
    "    # get mask of problem blob\n",
    "    problem_info = coords.loc[[v_id], [label_key, 't']]\n",
    "    problem_label = problem_info[label_key].values[0]\n",
    "    problem_t = problem_info['t'].values[0]\n",
    "    if (ct := len(problem_info)) > 1:\n",
    "        raise ValueError(f\"Solution label {problem_label} appears {ct} times in frame {problem_t}.\")\n",
    "    mask = sol_ims[problem_t] == problem_label\n",
    "    gt_frame = gt_ims[problem_t]\n",
    "    gt_ov_labels, _ = get_labels_with_overlap(gt_frame, mask)\n",
    "    gt_v_ids = []\n",
    "    for label in gt_ov_labels:\n",
    "        row = gt_coords[(gt_coords.label == label) & (gt_coords.t==problem_t)]\n",
    "        if (ct := len(row)) > 1:\n",
    "            raise ValueError(f\"GT label {label} appears {ct} times in frame {problem_t}.\")\n",
    "        vid = row.index.values[0]\n",
    "        gt_v_ids.append(vid)\n",
    "    return gt_v_ids\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a merge on vertex `v` is a result of undersegmentation, we expect to be able to find two (or potentially more) GT vertices with bounding boxes overlapping `v` - the one matching `v` itself, and the one matching the unidentified cell. \n",
    "\n",
    "Below we check the overlapping GT vertices for each merge vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching GT vertices for 467: [467, 468]\n",
      "Matching GT vertices for 576: [577]\n",
      "Matching GT vertices for 619: [621]\n",
      "Matching GT vertices for 2314: [2321]\n",
      "Matching GT vertices for 2514: [2522]\n",
      "Matching GT vertices for 2585: [2594]\n",
      "Matching GT vertices for 2667: [2677]\n",
      "Matching GT vertices for 2757: [2769]\n",
      "Matching GT vertices for 3628: [3646]\n",
      "Matching GT vertices for 3872: [3892]\n",
      "Matching GT vertices for 4075: [4097]\n",
      "Matching GT vertices for 4208: [4234]\n",
      "Matching GT vertices for 4669: [4700]\n",
      "Matching GT vertices for 4784: [4816]\n",
      "Matching GT vertices for 4788: [4820]\n",
      "Matching GT vertices for 4901: [4934]\n",
      "Matching GT vertices for 4906: [4939]\n",
      "Matching GT vertices for 5021: [5054]\n",
      "Matching GT vertices for 5113: [5146]\n",
      "Matching GT vertices for 5232: [5266]\n",
      "Matching GT vertices for 5353: [5388]\n",
      "Matching GT vertices for 6720: [6756]\n",
      "Matching GT vertices for 6769: [6805]\n",
      "Matching GT vertices for 6847: [6883]\n",
      "Matching GT vertices for 6976: [7012]\n",
      "Matching GT vertices for 6980: [7016]\n",
      "Unmatched: 0\n",
      "Matched: 25\n",
      "Multi-matched: 1\n"
     ]
    }
   ],
   "source": [
    "count_no_match = 0\n",
    "count_single_match = 0\n",
    "count_multi_match = 0\n",
    "for i, _ in merge_rows.iterrows():\n",
    "    gt_matched = get_gt_match_vertices(coords, gt_coords, sol_ims, gt_ims, i)\n",
    "    print(f'Matching GT vertices for {i}: {gt_matched}')\n",
    "    ct = len(gt_matched)\n",
    "    if ct == 0:\n",
    "        count_no_match += 1\n",
    "    elif ct == 1:\n",
    "        count_single_match += 1\n",
    "    else:\n",
    "        count_multi_match += 1\n",
    "print(f\"Unmatched: {count_no_match}\\nMatched: {count_single_match}\\nMulti-matched: {count_multi_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have matched every vertex (meaning we can be confident the merge vertices are real vertices in the ground truth graph), but only one of the merge vertices has an additional overlapping vertex i.e. was undersegmented by this overlap measure.\n",
    "\n",
    "So, we need to be a bit less strict with our matching criteria, and match GT vertices within a given tolerance of the merge vertex. Keeping in mind we are trying not to make false associations for unrelated vertices in our solution, we can limit this approximate match to only **GT vertices within a given distance of `v` that have no other matching vertices in the solution graph** - these are false negative vertices which, if added to the solution, cannot possibly be a mis-association of an existing vertex.\n",
    "\n",
    "**NOTE** We should probably **only** be doing this. If multiple computed vertices overlap the same gt vertex, how would we one identify that and two decide among them - of course in this check we dismiss a reference vertex if they have **any** overlap, so I think we're actually still running into this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertices in gt frame near to v that don't have matching vertices in solution\n",
    "def get_gt_unmatched_vertices(coords, gt_coords, sol_ims, gt_ims, v_id, dist):\n",
    "    from scipy.spatial import KDTree\n",
    "    from traccuracy.matchers._compute_overlap import get_labels_with_overlap\n",
    "    import numpy as np\n",
    "\n",
    "    problem_row = coords.loc[[v_id]]\n",
    "    problem_t = problem_row['t'].values[0]\n",
    "    cols = ['y', 'x']\n",
    "    if 'z' in coords.columns:\n",
    "        cols = ['z', 'y', 'x']\n",
    "    problem_coords = tuple(problem_row[cols].values[0])\n",
    "    \n",
    "    # build kdt from gt frame\n",
    "    gt_frame_coords = gt_coords[gt_coords['t'] == problem_t][cols]\n",
    "    coord_indices, *coord_tuples = zip(*list(gt_frame_coords.itertuples(name=None)))\n",
    "    coord_tuples = np.asarray(list(zip(*coord_tuples)))\n",
    "    coord_indices = np.asarray(coord_indices)\n",
    "\n",
    "    # get nearby vertices\n",
    "    gt_tree = KDTree(coord_tuples)\n",
    "    potential_unmatched = coord_indices[gt_tree.query_ball_point(problem_coords, dist, return_sorted=True)]\n",
    "    \n",
    "    unmatched = []\n",
    "    problem_frame = sol_ims[problem_t]\n",
    "    # check if they don't overlap with any solution vertices i.e. they are a fn\n",
    "    for v in potential_unmatched:\n",
    "        v_label = gt_coords.loc[[v], ['label']].values[0]\n",
    "        mask = gt_ims[problem_t] == v_label\n",
    "        _, sol_overlaps = get_labels_with_overlap(mask, problem_frame)\n",
    "        if not len(sol_overlaps):\n",
    "            unmatched.append(v)\n",
    "    return unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_unmatched_vertices_near_parent(coords, gt_coords, sol_ims, gt_ims, v_id, v_parents, dist, label_key='label'):\n",
    "    from scipy.spatial import KDTree\n",
    "    from traccuracy.matchers._compute_overlap import get_labels_with_overlap\n",
    "    import numpy as np\n",
    "\n",
    "    problem_row = coords.loc[[v_id]]\n",
    "    problem_t = problem_row['t'].values[0]\n",
    "    cols = ['y', 'x']\n",
    "    if 'z' in coords.columns:\n",
    "        cols = ['z', 'y', 'x']\n",
    "    parent_rows = coords.loc[v_parents]\n",
    "    parent_coords = parent_rows[cols].values\n",
    "    \n",
    "    # build kdt from gt frame\n",
    "    gt_frame_coords = gt_coords[gt_coords['t'] == problem_t][cols]\n",
    "    coord_indices, *coord_tuples = zip(*list(gt_frame_coords.itertuples(name=None)))\n",
    "    coord_tuples = np.asarray(list(zip(*coord_tuples)))\n",
    "    coord_indices = np.asarray(coord_indices)\n",
    "\n",
    "    # get nearby vertices close to both parents of v\n",
    "\n",
    "    gt_tree = KDTree(coord_tuples)\n",
    "    nearby = [n_index for n_list in gt_tree.query_ball_point(parent_coords, dist, return_sorted=True) for n_index in n_list]\n",
    "    potential_unmatched = coord_indices[nearby]\n",
    "    unmatched = []\n",
    "    problem_frame = sol_ims[problem_t]\n",
    "    # check if they don't overlap with any solution vertices i.e. they are a fn\n",
    "    for v in potential_unmatched:\n",
    "        v_label = gt_coords.loc[[v], ['label']].values[0]\n",
    "        mask = gt_ims[problem_t] == v_label\n",
    "        _, sol_overlaps = get_labels_with_overlap(mask, problem_frame)\n",
    "        if not len(sol_overlaps) and v not in unmatched:\n",
    "            unmatched.append(v)\n",
    "    return unmatched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we check whether unmatched GT vertices exist for the merge vertices above for different distance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_none = []\n",
    "# counts_one = []\n",
    "# counts_multi = []\n",
    "# dists = [10, 20, 25, 30, 35, 40, 50, 60, 70]\n",
    "# for dist in dists:\n",
    "#     count_no_unmatched = 0\n",
    "#     count_one_unmatched = 0\n",
    "#     count_multi_unmatched = 0\n",
    "#     for i, _ in merge_rows.iterrows():\n",
    "#         parent_ids = [v for v in graph._g.neighbors(i, mode='in') if graph._g.es[graph._g.get_eid(v, i)]['flow'] > 0]\n",
    "#         unmatched_gt = get_gt_unmatched_vertices_near_parent(coords, gt_coords, sol_ims, gt_ims, i, parent_ids, dist)\n",
    "#         ct = len(unmatched_gt)\n",
    "#         if ct == 0:\n",
    "#             count_no_unmatched += 1\n",
    "#         elif ct == 1:\n",
    "#             count_one_unmatched += 1\n",
    "#         else:\n",
    "#             count_multi_unmatched += 1\n",
    "#             # print(f\"At distance {dist}, unmatched GT near {i}: {unmatched_gt}\")\n",
    "#     counts_none.append(count_no_unmatched)\n",
    "#     counts_one.append(count_one_unmatched)\n",
    "#     counts_multi.append(count_multi_unmatched)\n",
    "# for i, dist in enumerate(dists):\n",
    "#     print(f\"Distance: {dist}\\nNone: {counts_none[i]}, One: {counts_one[i]}, Multi: {counts_multi[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the quick exploration above it looks like for this dataset, a distance of 40px captures many close-by unmatched vertices without finding multiple for a given vertex - which is more likely to be an unrelated vertex. Given the two functions above, let's see how many merge vertices have >1 associated GT vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_no_match = 0\n",
    "# count_single_match = 0\n",
    "# count_multi_match = 0\n",
    "# for i, _ in merge_rows.iterrows():\n",
    "#     gt_matched = get_gt_match_vertices(coords, gt_coords, sol_ims, gt_ims, i)\n",
    "#     # print(f'Matching GT vertices for {i}: {gt_matched}')\n",
    "#     if len(gt_matched) == 1:\n",
    "#         parent_ids = [v for v in graph._g.neighbors(i, mode='in') if graph._g.es[graph._g.get_eid(v, i)]['flow'] > 0]\n",
    "#         gt_unmatched = get_gt_unmatched_vertices_near_parent(coords, gt_coords, sol_ims, gt_ims, i, parent_ids, 50)\n",
    "#     else:\n",
    "#         gt_unmatched = []\n",
    "#     # print(f'Unmatched GT vertices for {i}: {gt_unmatched}')\n",
    "#     ct = len(gt_matched) + len(gt_unmatched)\n",
    "#     if ct == 0:\n",
    "#         count_no_match += 1\n",
    "#     elif ct == 1:\n",
    "#         count_single_match += 1\n",
    "#     else:\n",
    "#         count_multi_match += 1\n",
    "# print(f\"Unmatched: {count_no_match}\\nMatched: {count_single_match}\\nMulti-matched: {count_multi_match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Vertices\n",
    "\n",
    "As we can see, after using the more relaxed matching measure when only one overlapping GT vertex is found, we find two associated vertices for half of the merge vertices, and a single vertex for the rest. Now we need to decide what to do with them.\n",
    "\n",
    "Merge vertices **must** split on the next frame and this occurs in two (currently observed) ways in the dataset:\n",
    "\n",
    "- A cell is undersegmented for a single frame, and the merge divides into its two constituents on the next frame\n",
    "- A cell is undersegmented for multiple frames, and the extra flow in the merge vertex is shunted to a cell that divides in the next frame\n",
    "  - which **should** be division flow\n",
    "\n",
    "For now, we make minimal changes by simply introducing the additional vertices and fixing their incoming and outgoing edges. Introduced vertex `v'` is matched to `v`s furthest parent. Outgoing edges are slightly more complex.\n",
    "\n",
    "When neither of `v`s current children are merge vertices, we connect `v` to its closest child, and `v'` to the other child. When a next vertex **is** a merge vertex, it means frame `t+1` does not contain a reasonable split for `v`, and the flow was sent elsewhere to cope. As a result, we terminate `v`s predecessor `u` with the longest edge to `v` i.e. `u` flows to target - this \"divests\" it of any additional flow. We also do this with `v`s furthest away parent if there is no additional vertex introduced - implying there is no reasonable split available for `v` at time `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_label = 0\n",
    "last_index = 0\n",
    "v_info = None\n",
    "oracle = {}\n",
    "for i, _ in merge_rows.iterrows():\n",
    "    gt_matched = get_gt_match_vertices(coords, gt_coords, sol_ims, gt_ims, i)\n",
    "    parent_ids = [v for v in graph._g.neighbors(i, mode='in') if graph._g.es[graph._g.get_eid(v, i)]['flow'] > 0]\n",
    "    gt_unmatched = get_gt_unmatched_vertices_near_parent(coords, gt_coords, sol_ims, gt_ims, i, parent_ids, 50)\n",
    "    problem_v = coords.loc[[i]]\n",
    "    problem_coords = tuple(problem_v[['y', 'x']].values[0])\n",
    "\n",
    "    # we couldn't find a match for this vertex at all, we should just delete it\n",
    "    if not len(gt_matched) and not len(gt_unmatched):\n",
    "        decision = 'delete'\n",
    "    # we've only found one vertex nearby, it's v itself\n",
    "    elif len(gt_matched) + len(gt_unmatched) == 1:\n",
    "        decision = 'terminate'\n",
    "    # more than one \"true\" vertex overlaps v, a vertex should be introduced\n",
    "    elif len(gt_matched) > 1:\n",
    "        # closest match is `v`, second closest gets introduced\n",
    "        distances_to_v = [np.linalg.norm(\n",
    "                            np.asarray(problem_coords) - np.asarray(gt_coords.loc[[v], ['y', 'x']].values[0])\n",
    "                        ) for v in gt_matched]\n",
    "        second_closest = gt_matched[np.argsort(distances_to_v)[1]]\n",
    "        v_info = gt_coords.loc[second_closest]\n",
    "        decision = 'introduce'\n",
    "    # we didn't find >1 overlap, but we've found an unmatched GT vertex nearby\n",
    "    elif len(gt_unmatched):\n",
    "        # we just take the closest\n",
    "        v_id = gt_unmatched[0]\n",
    "        v_info = gt_coords.loc[v_id]\n",
    "        decision = 'introduce'\n",
    "\n",
    "    if v_info is not None:\n",
    "        if last_label == 0:\n",
    "            next_label = coords['label'].max() + 1\n",
    "            # hypervertices...\n",
    "            new_index = max(coords.index.values) + 5\n",
    "        else:\n",
    "            next_label = last_label + 1\n",
    "            new_index = last_index + 1\n",
    "\n",
    "        last_label = next_label\n",
    "        last_index = new_index\n",
    "\n",
    "    oracle[i] = {\n",
    "        'decision': decision,\n",
    "        'v_info': None if v_info is None else (new_index, list(v_info[['t', 'y', 'x']]) + [next_label]),\n",
    "        'parent': None\n",
    "    }\n",
    "    v_info = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing just vertices - no edge fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduce_vertices = dict(filter(lambda item: item[1]['decision'] == 'introduce', oracle.items()))\n",
    "\n",
    "merge_vids = []\n",
    "new_vids = []\n",
    "new_t = []\n",
    "y = []\n",
    "x = []\n",
    "new_label = []\n",
    "for key, v_info in introduce_vertices.items():\n",
    "    merge_vids.append(key)\n",
    "    v_info = v_info['v_info']\n",
    "    new_vids.append(v_info[0])\n",
    "    info_list = v_info[1]\n",
    "    new_t.append(int(info_list[0]))\n",
    "    y.append(info_list[1])\n",
    "    x.append(info_list[2])\n",
    "    new_label.append(info_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>merge_id</th>\n      <th>new_id</th>\n      <th>t</th>\n      <th>y</th>\n      <th>x</th>\n      <th>new_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>467</td>\n      <td>8606</td>\n      <td>9</td>\n      <td>505.0</td>\n      <td>907.0</td>\n      <td>390</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>576</td>\n      <td>8607</td>\n      <td>11</td>\n      <td>505.0</td>\n      <td>907.0</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2314</td>\n      <td>8608</td>\n      <td>37</td>\n      <td>435.0</td>\n      <td>177.0</td>\n      <td>392</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2514</td>\n      <td>8609</td>\n      <td>39</td>\n      <td>509.0</td>\n      <td>906.0</td>\n      <td>393</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2585</td>\n      <td>8610</td>\n      <td>40</td>\n      <td>506.0</td>\n      <td>911.0</td>\n      <td>394</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   merge_id  new_id   t      y      x  new_label\n0       467    8606   9  505.0  907.0        390\n1       576    8607  11  505.0  907.0        391\n2      2314    8608  37  435.0  177.0        392\n3      2514    8609  39  509.0  906.0        393\n4      2585    8610  40  506.0  911.0        394"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle_intro_df = pd.DataFrame({\n",
    "    'merge_id': merge_vids,\n",
    "    'new_id': new_vids,\n",
    "    't': new_t,\n",
    "    'y': y,\n",
    "    'x': x,\n",
    "    'new_label': new_label\n",
    "})\n",
    "oracle_intro_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 48022, {'cost': 120.29703974082108, 'var_name': 'e_43.78_44.318', 'label': '120.2', 'flow': 0}) 2803 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 48037, {'cost': 167.97343896117354, 'var_name': 'e_43.79_44.318', 'label': '167.9', 'flow': 0}) 2804 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 48047, {'cost': 130.07172618650856, 'var_name': 'e_43.88_44.318', 'label': '130.0', 'flow': 0}) 2805 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 48467, {'cost': 218.18774836685924, 'var_name': 'e_43.228_44.318', 'label': '218.1', 'flow': 0}) 2847 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 48591, {'cost': 53.96202604113287, 'var_name': 'e_43.307_44.318', 'label': '53.96', 'flow': 0}) 2860 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 48599, {'cost': 43.6193398920349, 'var_name': 'e_43.308_44.318', 'label': '43.61', 'flow': 0}) 2861 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 48610, {'cost': 62.6603460350025, 'var_name': 'e_43.317_44.318', 'label': '62.66', 'flow': 0}) 2862 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 48618, {'cost': 1.0949415855880131, 'var_name': 'e_43.318_44.318', 'label': '1.094', 'flow': 1.0}) 2863 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 2960, {'cost': 337.5853658536585, 'var_name': 'e_a_44.318', 'label': '337.', 'flow': 0}) 8603 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 49895, {'cost': 45.08721026889921, 'var_name': 'e_d_44.318', 'label': '45.08', 'flow': 0}) 8605 2959\n",
      "igraph.Vertex(<igraph.Graph object at 0x7fcdb1a3f040>, 2959, {'label': '44_318', 'coords': array([337.58536585, 760.78292683]), 'pixel_value': 318, 't': 44, 'is_source': False, 'is_target': False, 'is_appearance': False, 'is_division': False, 'name': None})\n"
     ]
    }
   ],
   "source": [
    "for e in graph._g.incident(2959, mode='in'):\n",
    "    print(graph._g.es[e], graph._g.es[e].source, graph._g.es[e].target)\n",
    "print(graph._g.vs[2959])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rebuilding frames: 100%|██████████| 26/26 [00:02<00:00,  9.49it/s]\n"
     ]
    }
   ],
   "source": [
    "introduce_vertices = dict(filter(lambda item: item[1]['decision'] == 'introduce', oracle.items()))\n",
    "introduce_oracle = {item['v_info'][0]: (int(item['v_info'][1][0]), item['v_info'][1][1:-1], item['v_info'][1][-1]) for item in introduce_vertices.values()}\n",
    "graph.introduce_vertices(introduce_oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph._g.neighbors(graph._g.vs[8520], mode='in')\n",
    "# print(graph._g.vs[-1])\n",
    "# print(graph._g.vs[8621])\n",
    "# graph._g.vs[-60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing vertices and fixing edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_vertex(merge_v, graph, oracle):\n",
    "    oracle_info = oracle[merge_v]\n",
    "    new_vid, info = oracle_info['v_info']\n",
    "    t = int(info[0])\n",
    "    coords = tuple(info[1:3])\n",
    "    new_label = info[3]\n",
    "\n",
    "    get_flow = lambda x, y: graph._g.es[graph._g.get_eid(x, y)]['flow']\n",
    "    get_distance = lambda x, y: np.linalg.norm(np.asarray(x['coords'])) - np.linalg.norm(np.asarray(y['coords']))\n",
    "\n",
    "    children = [graph._g.vs[v] for v in graph._g.neighbors(merge_v, 'out') if get_flow(merge_v, v) > 0]\n",
    "\n",
    "    parents = [graph._g.vs[v] for v in graph._g.neighbors(merge_v, 'in') if get_flow(v, merge_v) > 0]\n",
    "    # merge_v has been dealt with, it might have a new parent to assign\n",
    "    if len(parents) < 2:\n",
    "        if oracle[merge_v]['parent']:\n",
    "            new_parent = oracle[merge_v]['parent']\n",
    "        # if it doesn't that means there's a vertex being introduced, but we don't know who to parent it to?\n",
    "        else:\n",
    "            new_parent = None\n",
    "            raise ValueError(f\"Vertex {merge_v} only has parents {parents}. New vertex {new_vid}:{v_info} will have no parent connnection!\")\n",
    "    else:\n",
    "        new_parent = parents[0].index if get_distance(parents[0], graph._g.vs[merge_v]) > get_distance(parents[1], graph._g.vs[merge_v]) else parents[1].index\n",
    "\n",
    "    # add vertex\n",
    "    graph.introduce_vertex(new_vid, t, coords, new_label)\n",
    "    if graph._g.are_connected(new_parent, merge_v):\n",
    "        # delete current edge (new_parent, merge_v)\n",
    "        graph._g.delete_edges([(new_parent,merge_v)])\n",
    "    # add new edge (new_parent, introduced_v)\n",
    "    graph.add_edge(new_parent, new_vid, is_fixed=True)\n",
    "\n",
    "    is_merge_child1 = children[0].index  in oracle\n",
    "    is_merge_child2 = children[1].index  in oracle\n",
    "    # find longest edge\n",
    "    furthest_child = children[0].index if get_distance(graph._g.vs[merge_v], children[0]) > get_distance(graph._g.vs[merge_v], children[1]) else children[1].index\n",
    "    # neither child a merge\n",
    "    if not is_merge_child1 and not is_merge_child2:\n",
    "        # delete current edge (merge_v, furthest_child)\n",
    "        graph._g.delete_edges([(merge_v, furthest_child)])\n",
    "        # add new edge (new_v, furthest_child)\n",
    "        graph.add_edge(new_vid, furthest_child, is_fixed=True)\n",
    "    # a single child is merge\n",
    "    elif is_merge_child1 ^ is_merge_child2:\n",
    "        merge_child, other_child = (children[0].index, children[1].index) if is_merge_child1 else (children[1].index, children[0].index)\n",
    "        \n",
    "        # delete current edge (merge_v, merge_child)\n",
    "        graph._g.delete_edges([(merge_v, merge_child)])\n",
    "        # fix edge (merge_v, other_child) - cost =0?\n",
    "        graph._g.es[graph._g.get_eid(merge_v, other_child)]['cost'] = 0\n",
    "\n",
    "        # this merge child will also be getting split, so we'll have a new vertex to parent to new_vid\n",
    "        if oracle[merge_child]['decision'] == 'introduce':\n",
    "            oracle[merge_child]['parent'] = new_vid\n",
    "        # we'll have nowhere really to send this vertex, so send it to target\n",
    "        else:\n",
    "            # add edge (new_v, target)\n",
    "            graph.add_edge(new_vid, graph.target.index, is_fixed=True)\n",
    "    # both children merge\n",
    "    else:\n",
    "        # delete current edges (merge_v, both_children)\n",
    "        graph._g.delete_edges([(merge_v, children[0].index)])\n",
    "        graph._g.delete_edges([(merge_v, children[1].index)])\n",
    "\n",
    "        # add edge new_v - target\n",
    "        graph.add_edge(new_vid, graph.target.index, is_fixed=True)\n",
    "        # add edge merge_v - target\n",
    "        graph.add_edge(new_vid, graph.target.index, is_fixed=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got functions to deal with the decisions made by the oracle, we can apply them on the graph. We save the full graph for visualization purposes, and then build and solve the optimization model again on the updated graph.\n",
    "\n",
    "Because the graph is changing as we introduce/terminate vertices, it's important that our oracle can deal with these changes appropriately. In particular, by the time we get to a certain time frame and introduce a vertex, `v'`, it may no longer be a merge vertex, if its edges have been fixed as part of a previous introduction.\n",
    "\n",
    "To deal with this we first:\n",
    "- Introduce all vertices before terminating any. Introduced vertices are more likely to \"fix\" the local graph, and given our retrieval of them, we can be relatively sure they **need** to be there. Termination is a more fuzzy oracle decision, so we only make it if we really have to.\n",
    "- When introducing a vertex `v'` at `t` whose associated merge vertex `v` is no longer a merge vertex, it means we must have introduced a vertex in the previous frame - this new vertex should be the parent of `v'`\n",
    "    - We track this new parent in the oracle so that we can appropriately assign it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce_vertices = dict(filter(lambda item: item[1]['decision'] == 'introduce', oracle.items()))\n",
    "# for vid in introduce_vertices:\n",
    "#     introduce_vertex(vid, graph, oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still_merged = []\n",
    "# for merge_v in oracle.keys():\n",
    "#     incoming_vs = graph._g.neighbors(merge_v, mode='in')\n",
    "#     actual_incoming = []\n",
    "#     for v in incoming_vs:\n",
    "#         relevant_edge = graph._g.es[graph._g.get_eid(v, merge_v)]\n",
    "#         if relevant_edge['flow'] > 0 or relevant_edge['cost'] == 0:\n",
    "#             actual_incoming.append(v)\n",
    "#     if len(actual_incoming) > 1:\n",
    "#         print(f\"Vertex {merge_v} is still a merge vertex. Incoming vertices: {actual_incoming}\")\n",
    "#         print(f\"Oracle for {merge_v}: {oracle[merge_v]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "# full_path = \"/home/draga/PhD/data/cell_tracking_challenge/Fluo-N2DL-HeLa/01_RES_IC/oracle_introduced_full.graphml\"\n",
    "# del(graph._g.vs['name'])\n",
    "# del(graph._g.es['label'])\n",
    "# for v in graph._g.vs:\n",
    "#     v['y'] = v['coords'][0]\n",
    "#     v['x'] = v['coords'][1]\n",
    "#     for attr_name in graph._g.vertex_attributes():\n",
    "#         if isinstance(v[attr_name], np.bool_):\n",
    "#             v[attr_name] = int(v[attr_name])\n",
    "#         elif v[attr_name] is None:\n",
    "#             v[attr_name] = ''\n",
    "# for e in graph._g.es:\n",
    "#     for attr_name in graph._g.edge_attributes():\n",
    "#         if e[attr_name] is None:\n",
    "#             e[attr_name] = 0\n",
    "# del(graph._g.vs['coords'])\n",
    "# g_nx = graph._g.to_networkx()\n",
    "# nx.write_graphml_lxml(g_nx, full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# mig_copy = graph._g.copy()\n",
    "# mig_copy.delete_edges(lambda e: (e['flow'] == 0 and e['cost'] > 0))\n",
    "# to_delete_ids = [v.index for v in mig_copy.vs if v['label'] in ['division', 'source', 'appearance', 'target']]\n",
    "# mig_copy.delete_vertices(to_delete_ids)\n",
    "# mig_nx = mig_copy.to_networkx()\n",
    "# full_path = \"/home/draga/PhD/data/cell_tracking_challenge/Fluo-N2DL-HeLa/01_RES_IC/oracle_introduced_mig.graphml\"\n",
    "# nx.write_graphml_lxml(mig_nx, full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild Model, Solve and Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 25860 rows, 110553 columns and 424970 nonzeros\n",
      "Model fingerprint: 0x6a120820\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [2e-02, 4e+02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "\n",
      "Concurrent LP optimizer: dual simplex and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Presolve removed 139 rows and 2 columns\n",
      "Presolve time: 0.35s\n",
      "Presolved: 25721 rows, 110551 columns, 423471 nonzeros\n",
      "\n",
      "Ordering time: 0.04s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 3.044e+05\n",
      " Factor NZ  : 1.279e+06 (roughly 70 MB of memory)\n",
      " Factor Ops : 1.737e+08 (less than 1 second per iteration)\n",
      " Threads    : 3\n",
      "\n",
      "Barrier performed 0 iterations in 0.54 seconds (0.27 work units)\n",
      "Barrier solve interrupted - model solved by another algorithm\n",
      "\n",
      "\n",
      "Solved with dual simplex\n",
      "Solved in 9454 iterations and 0.54 seconds (0.33 work units)\n",
      "Optimal objective  3.099334333e+04\n"
     ]
    }
   ],
   "source": [
    "new_m, flow = graph._to_gurobi_model()\n",
    "new_m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sol_igraph_to_nx(graph):\n",
    "    for v in graph._g.vs:\n",
    "        v['y'] = v['coords'][0]\n",
    "        v['x'] = v['coords'][1]\n",
    "        for attr_name in graph._g.vertex_attributes():\n",
    "            if isinstance(v[attr_name], np.bool_):\n",
    "                v[attr_name] = int(v[attr_name])\n",
    "            elif v[attr_name] is None:\n",
    "                v[attr_name] = 0\n",
    "    for e in graph._g.es:\n",
    "        for attr_name in graph._g.edge_attributes():\n",
    "            if e[attr_name] is None:\n",
    "                e[attr_name] = 0\n",
    "    del(graph._g.vs['coords'])\n",
    "    del(graph._g.vs['name'])\n",
    "    del(graph._g.vs['label'])\n",
    "\n",
    "    del(graph._g.es['label'])\n",
    "    nx_g = graph._g.to_networkx(create_using=nx.DiGraph)\n",
    "    return nx_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save info on graph\n",
    "store_solution_on_graph(new_m, graph)\n",
    "nx_g = convert_sol_igraph_to_nx(graph)\n",
    "oracle_node_df = pd.DataFrame.from_dict(nx_g.nodes, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summing flow: 100%|██████████| 8964/8964 [01:15<00:00, 118.29it/s]\n"
     ]
    }
   ],
   "source": [
    "graph.save_flow_info(oracle_node_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 39310, {'cost': 120.29703974082108, 'var_name': 'e_43.78_44.318', 'flow': 0}) 2803 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 39325, {'cost': 167.97343896117354, 'var_name': 'e_43.79_44.318', 'flow': 0}) 2804 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 39335, {'cost': 130.07172618650856, 'var_name': 'e_43.88_44.318', 'flow': 0}) 2805 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 39755, {'cost': 218.18774836685924, 'var_name': 'e_43.228_44.318', 'flow': 0}) 2847 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 39879, {'cost': 53.96202604113287, 'var_name': 'e_43.307_44.318', 'flow': 0}) 2860 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 39887, {'cost': 43.6193398920349, 'var_name': 'e_43.308_44.318', 'flow': 0}) 2861 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 39898, {'cost': 62.6603460350025, 'var_name': 'e_43.317_44.318', 'flow': 0}) 2862 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 39906, {'cost': 1.0949415855880131, 'var_name': 'e_43.318_44.318', 'flow': 1.0}) 2863 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 2960, {'cost': 337.5853658536585, 'var_name': 'e_a_44.318', 'flow': 0}) 8603 2959\n",
      "igraph.Edge(<igraph.Graph object at 0x7fcdb1a3f040>, 41183, {'cost': 45.08721026889921, 'var_name': 'e_d_44.318', 'flow': 0}) 8605 2959\n",
      "igraph.Vertex(<igraph.Graph object at 0x7fcdb1a3f040>, 2959, {'pixel_value': 318, 't': 44, 'is_source': 0, 'is_target': 0, 'is_appearance': 0, 'is_division': 0, 'y': 337.5853658536585, 'x': 760.7829268292683})\n"
     ]
    }
   ],
   "source": [
    "for e in graph._g.incident(2959, mode='in'):\n",
    "    print(graph._g.es[e], graph._g.es[e].source, graph._g.es[e].target)\n",
    "print(graph._g.vs[2959])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = \"/home/draga/PhD/data/cell_tracking_challenge/Fluo-N2DL-HeLa/01_RES_IC/oracle_introduced_near_parent_no_edges.graphml\"\n",
    "nx.write_graphml_lxml(nx_g, full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merges = oracle_node_df[oracle_node_df['in-mig'] > 1]\n",
    "term_v = dict(filter(lambda item: item[1]['decision'] == 'terminate', oracle.items()))\n",
    "new_merges_no_term = new_merges.drop(list(term_v.keys()), errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel_value</th>\n      <th>t</th>\n      <th>is_source</th>\n      <th>is_target</th>\n      <th>is_appearance</th>\n      <th>is_division</th>\n      <th>y</th>\n      <th>x</th>\n      <th>_igraph_index</th>\n      <th>in-app</th>\n      <th>in-div</th>\n      <th>in-mig</th>\n      <th>out-mig</th>\n      <th>out-target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>632</th>\n      <td>363</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>500.765372</td>\n      <td>891.763754</td>\n      <td>632</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2687</th>\n      <td>363</td>\n      <td>41</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>492.375000</td>\n      <td>891.059524</td>\n      <td>2687</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2872</th>\n      <td>363</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>486.684524</td>\n      <td>892.791667</td>\n      <td>2872</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4113</th>\n      <td>266</td>\n      <td>55</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>541.792321</td>\n      <td>935.307155</td>\n      <td>4113</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4230</th>\n      <td>279</td>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>543.175439</td>\n      <td>971.371345</td>\n      <td>4230</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4339</th>\n      <td>265</td>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>507.379200</td>\n      <td>961.921600</td>\n      <td>4339</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4343</th>\n      <td>278</td>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>518.868056</td>\n      <td>1007.775463</td>\n      <td>4343</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5533</th>\n      <td>325</td>\n      <td>67</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>340.281899</td>\n      <td>759.038576</td>\n      <td>5533</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8612</th>\n      <td>396</td>\n      <td>42</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>505.000000</td>\n      <td>908.000000</td>\n      <td>8612</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      pixel_value   t is_source is_target is_appearance is_division  \\\n632           363  12         0         0             0           0   \n2687          363  41         0         0             0           0   \n2872          363  43         0         0             0           0   \n4113          266  55         0         0             0           0   \n4230          279  56         0         0             0           0   \n4339          265  57         0         0             0           0   \n4343          278  57         0         0             0           0   \n5533          325  67         0         0             0           0   \n8612          396  42     False     False         False       False   \n\n               y            x  _igraph_index  in-app  in-div  in-mig  out-mig  \\\n632   500.765372   891.763754            632     0.0     0.0     2.0      2.0   \n2687  492.375000   891.059524           2687     0.0     0.0     2.0      2.0   \n2872  486.684524   892.791667           2872     0.0     0.0     2.0      2.0   \n4113  541.792321   935.307155           4113     0.0     0.0     2.0      2.0   \n4230  543.175439   971.371345           4230     0.0     0.0     2.0      2.0   \n4339  507.379200   961.921600           4339     0.0     0.0     1.5      1.5   \n4343  518.868056  1007.775463           4343     0.0     0.0     1.5      1.5   \n5533  340.281899   759.038576           5533     0.0     1.0     2.5      3.5   \n8612  505.000000   908.000000           8612     0.0     0.0     2.0      2.0   \n\n      out-target  \n632            0  \n2687           0  \n2872           0  \n4113           0  \n4230           0  \n4339           0  \n4343           0  \n5533           0  \n8612           0  "
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_merges_no_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearby fn_vertices for merge vertex 632: [634, 635]\n",
      "Nearby fn vertices for merge vertex 2687: [2699]\n",
      "Nearby fn vertices for merge vertex 2872: [2887]\n",
      "Nearby fn vertices for merge vertex 4113: [4163]\n",
      "Merge vertex 4230 does not have a nearby vertex to introduce\n",
      "Merge vertex 4339 does not have a nearby vertex to introduce\n",
      "Merge vertex 4343 does not have a nearby vertex to introduce\n",
      "Merge vertex 5533 does not have a nearby vertex to introduce\n",
      "Merge vertex 8612 does not have a nearby vertex to introduce\n",
      "Unmatched: 5\n",
      "Matched: 3\n",
      "Multi-matched: 1\n"
     ]
    }
   ],
   "source": [
    "from ctc_fluo_metrics import introduce_gt_labels\n",
    "new_sol_ims = sol_ims.copy()\n",
    "introduce_gt_labels(nx_g, new_sol_ims, gt_ims)\n",
    "\n",
    "count_no_match = 0\n",
    "count_single_match = 0\n",
    "count_multi_match = 0\n",
    "for i, _ in new_merges_no_term.iterrows():\n",
    "    gt_overlaps = get_gt_match_vertices(oracle_node_df, gt_coords, new_sol_ims, gt_ims, i, label_key='pixel_value')\n",
    "    if len(gt_overlaps) == 1:\n",
    "        parent_ids = [v for v in graph._g.neighbors(i, mode='in') if graph._g.es[graph._g.get_eid(v, i)]['flow'] > 0]\n",
    "        gt_unmatched = get_gt_unmatched_vertices_near_parent(oracle_node_df, gt_coords, new_sol_ims, gt_ims, i, parent_ids, 50, label_key='pixel_value')\n",
    "        gt_overlaps = []\n",
    "    else:\n",
    "        gt_unmatched = []\n",
    "    # print(f'Unmatched GT vertices for {i}: {gt_unmatched}')\n",
    "    ct = len(gt_overlaps) + len(gt_unmatched)\n",
    "    if ct == 0:\n",
    "        count_no_match += 1\n",
    "        print(f'Merge vertex {i} does not have a nearby vertex to introduce')\n",
    "    elif ct == 1:\n",
    "        count_single_match += 1\n",
    "        print(f'Nearby fn vertices for merge vertex {i}: {gt_overlaps + gt_unmatched}')\n",
    "    else:\n",
    "        count_multi_match += 1\n",
    "        print(f'Nearby fn_vertices for merge vertex {i}: {gt_overlaps + gt_unmatched}')\n",
    "print(f\"Unmatched: {count_no_match}\\nMatched: {count_single_match}\\nMulti-matched: {count_multi_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_g = graph._g.to_networkx(create_using=nx.DiGraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_path = \"/home/draga/PhD/data/cell_tracking_challenge/Fluo-N2DL-HeLa/01_RES_IC/oracle_introduced_near_parent_no_edges.graphml\"\n",
    "nx.write_graphml_lxml(nx_g, full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_merge_vertex(merge_v, graph):\n",
    "    get_flow = lambda x, y: graph._g.es[graph._g.get_eid(x, y)]['flow']\n",
    "    get_distance = lambda x, y: np.linalg.norm(np.asarray(x['coords'])) - np.linalg.norm(np.asarray(y['coords']))\n",
    "\n",
    "    parents = [graph._g.vs[v] for v in graph._g.neighbors(merge_v, 'in') if get_flow(v, merge_v) > 0]\n",
    "    children = [graph._g.vs[v] for v in graph._g.neighbors(merge_v, 'out') if get_flow(merge_v, v) > 0]\n",
    "\n",
    "    furthest_child = children[0].index if get_distance(graph._g.vs[merge_v], children[0]) > get_distance(graph._g.vs[merge_v], children[1]) else children[1].index\n",
    "    furthest_parent = parents[0].index if get_distance(parents[0], graph._g.vs[merge_v]) > get_distance(parents[1], graph._g.vs[merge_v]) else parents[1].index\n",
    "    \n",
    "    # Delete edge (furthest_parent, merge_v)\n",
    "    graph._g.delete_edges([(furthest_parent, merge_v)])\n",
    "    # Add edge from furthest parent to target\n",
    "    graph.add_edge(furthest_parent, graph.target.index, is_fixed=True)\n",
    "    # Delete (merge_v, furthest_child)\n",
    "    graph._g.delete_edges([(merge_v, furthest_child)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "- ~~Finish introduce_vertex~~\n",
    "- ~~Write terminate_merge_vertex~~\n",
    "- [ ] How do we handle changes to interconnected merge vertices? I.e. making sure it's consistent\n",
    "  - Do any of these actions risk enforcing a potentially unsatisfiable set of edges\n",
    "- ~~Save edited graph after running introduce~~\n",
    "- ~~Save edited graph after running terminate~~\n",
    "- ~~Add code to rebuild and rerun solution~~\n",
    "- [ ] Check edge labels with `None` in them?\n",
    "- [ ] Update coord rows after introducing vertices so we can save flow info\n",
    "- [ ] Visualize/metric/check new solution\n",
    "  - [ ] Potentially fix metric\n",
    "  - [ ] Check original solution fp/tp/fn edges vs. oracle solution fp/tp/fn edges vs. re-solved fp/tp/fn edges\n",
    "- [ ] Make edge deletion fixed 0 flow\n",
    "- [ ] Improve edge deletion/addition to do all at once\n",
    "\n",
    "- [ ] Update live model and re-solve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}